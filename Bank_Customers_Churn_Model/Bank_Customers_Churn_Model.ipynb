{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta Bank Churn Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beta Bank customers are leaving: little by little, chipping away every month. The bankers figured out it’s cheaper to save the existing customers rather than to attract new ones.\n",
    "We need to predict whether a customer will leave the bank soon. We have the data on clients’ past behavior and termination of contracts with the bank.\n",
    "Our task is to build a model with the maximum possible F1 score. To pass the project, we need an F1 score of at least 0.59, when checked for a test set.\n",
    "Additionally, we will measure the AUC-ROC metric and compare it with the F1.\n",
    "\n",
    "**Project Goal**: Build a model to predict whether a customer will leave the bank soon, based on data on clients’ past behavior and termination of contracts with the bank, with the maximum possible F1 score (at least 0.59, when checked for a test set). Additionally, AUC-ROC metric should be measured and compared with the F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading libraries\n",
    "from scipy import stats as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data into a DataFrame: \n",
    "df = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at a sample of the data:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# General info of the data:\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for explicit duplicates: \n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 10k entries and 14 columns, only one ('Tenure') with about 9% missing values. No explicit duplicates. Data includes:\n",
    "\n",
    "Features:\n",
    "- RowNumber — data string index\n",
    "- CustomerId — unique customer identifier\n",
    "- Surname — surname\n",
    "- CreditScore — credit score\n",
    "- Geography — country of residence\n",
    "- Gender — gender\n",
    "- Age — age\n",
    "- Tenure — period of maturation for a customer’s fixed deposit (years)\n",
    "- Balance — account balance\n",
    "- NumOfProducts — number of banking products used by the customer\n",
    "- HasCrCard — customer has a credit card\n",
    "- IsActiveMember — customer’s activeness\n",
    "- EstimatedSalary — estimated salary\n",
    "\n",
    "Target:\n",
    "- Exited — сustomer has left\n",
    "\n",
    "**Preparing Data**: Following inspection of the data, we will perform the following steps\n",
    "\n",
    "1. Droping the data with missing values on 'Tenure', since it will keep ~91% of the data and it will be complete.\n",
    "2. Droping the 'RowNumber', 'CustomerId' and 'Surname' columns since they have no real relevance to predicting churn and we dont want them to confuse the model.\n",
    "3. OHE encoding to the other categorical columns ('Geography' and 'Gender').\n",
    "4. Splitting the data randomly into 3 sets: training, validation, test (60:20:20).\n",
    "5. Standardize the numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9091 entries, 0 to 9998\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          9091 non-null int64\n",
      "CustomerId         9091 non-null int64\n",
      "Surname            9091 non-null object\n",
      "CreditScore        9091 non-null int64\n",
      "Geography          9091 non-null object\n",
      "Gender             9091 non-null object\n",
      "Age                9091 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            9091 non-null float64\n",
      "NumOfProducts      9091 non-null int64\n",
      "HasCrCard          9091 non-null int64\n",
      "IsActiveMember     9091 non-null int64\n",
      "EstimatedSalary    9091 non-null float64\n",
      "Exited             9091 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Droping the data with the missing values on 'Tenure': \n",
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, all 14 columns have full 9091 entries, no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9091, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Droping the first 3 columns:\n",
    "df = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, 11 relevant columns remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9091 entries, 0 to 9998\n",
      "Data columns (total 12 columns):\n",
      "CreditScore          9091 non-null int64\n",
      "Age                  9091 non-null int64\n",
      "Tenure               9091 non-null float64\n",
      "Balance              9091 non-null float64\n",
      "NumOfProducts        9091 non-null int64\n",
      "HasCrCard            9091 non-null int64\n",
      "IsActiveMember       9091 non-null int64\n",
      "EstimatedSalary      9091 non-null float64\n",
      "Exited               9091 non-null int64\n",
      "Geography_Germany    9091 non-null uint8\n",
      "Geography_Spain      9091 non-null uint8\n",
      "Gender_Male          9091 non-null uint8\n",
      "dtypes: float64(3), int64(6), uint8(3)\n",
      "memory usage: 736.9 KB\n"
     ]
    }
   ],
   "source": [
    "# OHE encoding:\n",
    "df_ohe = pd.get_dummies(df, drop_first=True)\n",
    "df_ohe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, after OHE encoding (avoiding dummies traps - droping first) we have 12 columns altogether. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (5454, 11)\n",
      "Training target shape: (5454,)\n",
      "Validation features shape: (1818, 11)\n",
      "Validation target shape: (1818,)\n",
      "Test features shape: (1819, 11)\n",
      "Test target shape: (1819,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the data randomly into 3 sets: training, validation, test (60:20:20), and checking their sizes: \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We want to split the data in 60:20:20 for train:valid:test dataset\n",
    "train_size=0.6\n",
    "\n",
    "# For convenience we will symbol 'features' as 'X', and 'target' as 'y'\n",
    "X = df_ohe.drop(['Exited'], axis=1)\n",
    "y = df_ohe['Exited']\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.6, random_state=12345, stratify=y)\n",
    "\n",
    "# Now since we want the valid and test size to be equal (20% each of overall data). \n",
    "# we have to define valid_size=0.5 (that is 50% of remaining data)\n",
    "test_size = 0.5\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5, random_state=12345, stratify=y_rem)\n",
    "\n",
    "print('Training features shape:', X_train.shape), print('Training target shape:', y_train.shape)\n",
    "print('Validation features shape:', X_valid.shape), print('Validation target shape:', y_valid.shape)\n",
    "print('Test features shape:', X_test.shape), print('Test target shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, the 9091 entries are randomly divided into 3 sets, in ratio 60:20:20 for train:valid:test datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9723</td>\n",
       "      <td>-1.292898</td>\n",
       "      <td>-0.660843</td>\n",
       "      <td>0.686341</td>\n",
       "      <td>0.786636</td>\n",
       "      <td>-0.910943</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.223548</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1224</td>\n",
       "      <td>-1.563714</td>\n",
       "      <td>0.778434</td>\n",
       "      <td>1.034232</td>\n",
       "      <td>0.833795</td>\n",
       "      <td>-0.910943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.383021</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8377</td>\n",
       "      <td>1.581914</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>-0.357331</td>\n",
       "      <td>-1.222967</td>\n",
       "      <td>0.789359</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.308331</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8014</td>\n",
       "      <td>0.842379</td>\n",
       "      <td>0.010820</td>\n",
       "      <td>-1.053112</td>\n",
       "      <td>0.807063</td>\n",
       "      <td>-0.910943</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.430980</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2491</td>\n",
       "      <td>-0.397123</td>\n",
       "      <td>-1.236554</td>\n",
       "      <td>-0.357331</td>\n",
       "      <td>-1.222967</td>\n",
       "      <td>0.789359</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392642</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "9723    -1.292898 -0.660843  0.686341  0.786636      -0.910943          0   \n",
       "1224    -1.563714  0.778434  1.034232  0.833795      -0.910943          1   \n",
       "8377     1.581914  0.106771 -0.357331 -1.222967       0.789359          1   \n",
       "8014     0.842379  0.010820 -1.053112  0.807063      -0.910943          1   \n",
       "2491    -0.397123 -1.236554 -0.357331 -1.222967       0.789359          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "9723               0        -0.223548                  0                0   \n",
       "1224               0         1.383021                  0                1   \n",
       "8377               1        -0.308331                  0                1   \n",
       "8014               1        -0.430980                  0                1   \n",
       "2491               1         1.392642                  0                1   \n",
       "\n",
       "      Gender_Male  \n",
       "9723            1  \n",
       "1224            0  \n",
       "8377            1  \n",
       "8014            0  \n",
       "2491            0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize the numeric features:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance',\n",
    "       'NumOfProducts', 'EstimatedSalary']\n",
    "# Create an instance of the StandardScaler() class and tune it using the training data.\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[numeric])\n",
    "\n",
    "# Transform train, validation and test data: \n",
    "X_train[numeric] = scaler.transform(X_train[numeric])\n",
    "X_valid[numeric] = scaler.transform(X_valid[numeric])\n",
    "X_test[numeric] = scaler.transform(X_test[numeric])\n",
    "#pd.options.mode.chained_assignment = None\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all relevant numeric features are standardized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating the balance of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.796062\n",
      "1    0.203938\n",
      "Name: Exited, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check target class frequencies:\n",
    "class_frequency = y.value_counts(normalize=True) \n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The positive answers (exited) are about a fifth (!) of all the customers. The classes are imbalanced 4:1 (negative:positive), while the critical thing for our bank is not to miss optional leavers (positive).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model without taking into account the imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will investigate training a model without taking into account the imbalance. We will try first with Random Forest Classifier, first with 20 trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5911330049261084\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with 20 trees: \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestClassifier(random_state=12345, n_estimators=20) \n",
    "\n",
    "# Train the model on the training set:\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Investigate model f1_score for validation set: \n",
    "predicted_valid = model.predict(X_valid)\n",
    "print(f1_score(y_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got F1 of 0.5911 on the validation set (which is already above our treshold, first time any model is using any part of the data). Let's see if 100 trees will improve the F1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5957446808510638\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with 100 trees: \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestClassifier(random_state=12345, n_estimators=100) \n",
    "\n",
    "# Train the model on the training set:\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Investigate model f1_score for validation set: \n",
    "predicted_valid = model.predict(X_valid)\n",
    "print(f1_score(y_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 on validation set is a bit better (0.5957). Before we move to improve the balance to try and improve our model quality - we will also calculate the AUC-ROC score before improving balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8371803845065598\n"
     ]
    }
   ],
   "source": [
    "# Measuring AUC-ROC metric on the validation set: \n",
    "from sklearn.metrics import roc_auc_score\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=12345)\n",
    "model.fit(X_train, y_train)\n",
    "probabilities_test = model.predict_proba(X_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(y_test, probabilities_one_test)\n",
    "\n",
    "print(auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving model quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will try to fix the imbalance by using class weight adjustment and upsampling, then we will try to tue some hyperparameters (tree depth and number of trees). We will start with 20 trees, and only later tune the number of trees. All improvements will be trined on the training set and F1 investigated on the validation set.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing class imbalance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Weight Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.543859649122807\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with 20 trees with class_weight='balanced': \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestClassifier(random_state=12345, n_estimators=20, class_weight='balanced') \n",
    "\n",
    "# Train the model on the training set:\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Investigate model f1_score for validation set: \n",
    "predicted_valid = model.predict(X_valid)\n",
    "print(f1_score(y_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No improvement, F1 went down from 0.5911 (20 trees) to 0.544. We will continue to upsampling, giving the positive (exited) more power (X4 - following the 4:1 ratio between the classes), in order to minimize the risk of missing them.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59882005899705\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with 20 trees with upsampling: \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(\n",
    "    X_train, y_train, 4\n",
    ")\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestClassifier(random_state=12345, n_estimators=20) \n",
    "\n",
    "# Train the model on the training set:\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "\n",
    "# Investigate model f1_score for validation set: \n",
    "predicted_valid = model.predict(X_valid)\n",
    "print(f1_score(y_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, for 20 trees this is our best F1 (0.5988) on the validation set so far. We will move to tuning hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Hyperparameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will try - still with 20 trees - to choose optimal max_tree_depth: we will go through depths from 1 to 16 and check F1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.5433746425166825\n",
      "2 0.5515210991167812\n",
      "3 0.5737704918032787\n",
      "4 0.6025641025641026\n",
      "5 0.6081229418221735\n",
      "6 0.6072607260726073\n",
      "7 0.6228070175438596\n",
      "8 0.6341463414634148\n",
      "9 0.617169373549884\n",
      "10 0.6223277909738717\n",
      "11 0.6287128712871287\n",
      "12 0.646074646074646\n",
      "13 0.6216216216216216\n",
      "14 0.6198347107438017\n",
      "15 0.6253521126760563\n"
     ]
    }
   ],
   "source": [
    "# Try to choose optimal tree depth with random forest of 20 trees\n",
    "\n",
    "for depth in range(1, 16, 1):\n",
    "    model = RandomForestClassifier(n_estimators=20, max_depth=depth, random_state=12345)\n",
    "    model.fit(features_upsampled, target_upsampled)\n",
    "    predicted_valid = model.predict(X_valid)\n",
    "    print(depth, f1_score(y_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best one is depth of 12, F1=0.646 (improved from 0.5988). Let's check if here - maybe the combined impact of upsamling and class weight adjustment (that alone was not effective) might yield better F1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.5433746425166825\n",
      "2 0.5614385614385615\n",
      "3 0.5797705943691346\n",
      "4 0.5900216919739697\n",
      "5 0.6122448979591836\n",
      "6 0.6105499438832772\n",
      "7 0.6119733924611973\n",
      "8 0.6326767091541136\n",
      "9 0.6301050175029173\n",
      "10 0.6159420289855073\n",
      "11 0.6218905472636815\n",
      "12 0.6287978863936592\n",
      "13 0.631439894319683\n",
      "14 0.6145404663923182\n",
      "15 0.6073871409028728\n"
     ]
    }
   ],
   "source": [
    "# Try to choose optimal tree depth with random forest of 20 trees, adding class_weight='balanced':  \n",
    "\n",
    "for depth in range(1, 16, 1):\n",
    "    model = RandomForestClassifier(n_estimators=20, max_depth=depth, random_state=12345, class_weight='balanced')\n",
    "    model.fit(features_upsampled, target_upsampled)\n",
    "    predicted_valid = model.predict(X_valid)\n",
    "    print(depth, f1_score(y_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, no improvement. we will keep only the upsampling. balance improvemment methods. We will choose max tree depth of 12 (we got F1 of 0.646 - the highest so far for 20 trees). Let's see if 100 trees improve the F1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6394736842105263\n"
     ]
    }
   ],
   "source": [
    "# Check if 100 trees (with the optimal tree depth) improves f1_score:\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=12, random_state=12345)\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid = model.predict(X_valid)\n",
    "print(f1_score(y_valid, predicted_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 has changed from 0.646 to 0.639 - a small decrease. Maybe the optimal max tree depth is different for 100 trees (than the 12 trees that were best for 20 trees), let's investigate: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.5402650356778798\n",
      "2 0.5426052889324192\n",
      "3 0.5792235047219307\n",
      "4 0.5978494623655913\n",
      "5 0.6034858387799563\n",
      "6 0.6184649610678532\n",
      "7 0.6298342541436462\n",
      "8 0.6285714285714286\n",
      "9 0.628175519630485\n",
      "10 0.6257378984651712\n",
      "11 0.631578947368421\n",
      "12 0.6394736842105263\n",
      "13 0.63257065948856\n",
      "14 0.6395511921458626\n",
      "15 0.6246498599439777\n"
     ]
    }
   ],
   "source": [
    "# Try to choose optimal tree depth with random forest of 100 trees:  \n",
    "\n",
    "for depth in range(1, 16, 1):\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=depth, random_state=12345)\n",
    "    model.fit(features_upsampled, target_upsampled)\n",
    "    predicted_valid = model.predict(X_valid)\n",
    "    print(depth, f1_score(y_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not realy, here tree depth of 12 and 14 are best, but the highest F1 is only 0.63955 (on the validation set), which is lower than the 0.646 we got for 20 trees. Let's return to our best model so far:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.646074646074646\n"
     ]
    }
   ],
   "source": [
    "# The chosen model - RandomForestClassifier model of 20 trees and max tree depth of 12:\n",
    "model = RandomForestClassifier(n_estimators=20, max_depth=12, random_state=12345)\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid = model.predict(X_valid)\n",
    "print(f1_score(y_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are almost ready to check our model F1 on the test set, and our last developmant step will be to train the model (with our tuned hyperparameters) once more - this time on the concatenated train+validation set (just before evaluating the model on the test set), so as not to waste the validation set data. Of course, we will apply upsampling to the concatenated train+validation set too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=20,\n",
       "                       n_jobs=None, oob_score=False, random_state=12345,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the final model on the concatenated train+validation set, after upsampling it:\n",
    "\n",
    "# Concatenating train and valid:\n",
    "X_train_valid = pd.concat([X_train, X_valid])\n",
    "y_train_valid = pd.concat([y_train, y_valid])\n",
    "\n",
    "# Applying upsampling to the concatenated set:\n",
    "features_upsampled, target_upsampled = upsample(\n",
    "    X_train_valid, y_train_valid, 4\n",
    ")\n",
    "\n",
    "# Define the model and train it on the concatenated set:\n",
    "model = RandomForestClassifier(n_estimators=20, max_depth=12, random_state=12345)\n",
    "model.fit(features_upsampled, target_upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the chosen model on the test set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the first time we will use the test set, to test our model's F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6002587322121604\n"
     ]
    }
   ],
   "source": [
    "# test the chosen RandomForestClassifier model of 20 trees and max tree depth of 12 on the test set: \n",
    "model = RandomForestClassifier(n_estimators=20, max_depth=12, random_state=12345)\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "predicted_test = model.predict(X_test)\n",
    "print(f1_score(y_test, predicted_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, our F1 is 0.60, checked on the test set, and it is above our desired threshold. This is our final model. As requested - we will also measure the AUC-ROC and plot the ROC curve. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC-ROC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.845752483209483\n"
     ]
    }
   ],
   "source": [
    "# Measuring AUC-ROC metric on the test set: \n",
    "from sklearn.metrics import roc_auc_score\n",
    "model = RandomForestClassifier(n_estimators=20, max_depth=12, random_state=12345)\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "probabilities_test = model.predict_proba(X_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(y_test, probabilities_one_test)\n",
    "\n",
    "print(auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slight improvement in this measure from before the imbalance fixing (0.837) to our final model (0.846). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3dd3hUZfbA8e9J6C30lhA6Ir2EZgV7QRFBBOwF7P7Wgsu6tlV317prL9iwo4KFVRQbiqIgoUPovXdCSCPJnN8f90JCTIZJyMydmZzP8/DcMrccLskc7vvee15RVYwxxpjixHgdgDHGmPBmicIYY4xfliiMMcb4ZYnCGGOMX5YojDHG+GWJwhhjjF+WKIwxxvhlicJEHRFZJyKZInJARLaJyHgRqVFomxNE5EcRSRORVBH5n4h0KLRNLRF5RkQ2uMda7S7XD+3fyBhvWaIw0eoCVa0BdAO6A3879IGI9AO+Bb4AmgItgQXADBFp5W5TCfgB6AicA9QC+gG7gd7BClpEKgTr2MaUliUKE9VUdRswFSdhHPIE8I6qPquqaaq6R1XvA2YCD7nbXAkkAoNVNUVVfaq6Q1UfUdUpRZ1LRDqKyHciskdEtovIve768SLyaIHt+ovIpgLL60TkryKyEEh35ycWOvazIvKcOx8nIm+IyFYR2Swij4pI7DFeKmOKZYnCRDURSQDOBVa5y9WAE4BPitj8Y+BMd/4M4BtVPRDgeWoC3wPf4NyltMG5IwnUCOB8oDYwATjPPSZuEhgGfOBuOx7Idc/RHTgLuL4E5zKmRCxRmGj1uYikARuBHcCD7vq6OD/3W4vYZytwqP+hXjHbFGcgsE1Vn1bVLPdOZVYJ9n9OVTeqaqaqrgfmAoPdz04DMlR1pog0As4D/qKq6aq6A/gvMLwE5zKmRCxRmGh1karWBPoD7clPAHsBH9CkiH2aALvc+d3FbFOcZsDqUkXq2Fho+QOcuwyAkeTfTTQHKgJbRWSfiOwDXgUaHsO5jfHLEoWJaqr6M05TzVPucjrwO3BJEZsPI7+56HvgbBGpHuCpNgKtivksHahWYLlxUaEWWv4E6O82nQ0mP1FsBLKB+qpa2/1TS1U7BhinMSVmicKUB88AZ4pIV3d5LHCViNwuIjVFpI7b2dwP+Ie7zbs4X8qTRKS9iMSISD0RuVdEziviHF8CTUTkLyJS2T1uH/ez+Th9DnVFpDHwl6MFrKo7gZ+At4C1qrrUXb8V54mtp93Hd2NEpLWInFqK62JMQCxRmKjnfum+AzzgLv8KnA1cjNMPsR6nU/gkVV3pbpON06G9DPgO2A/8gdOE9ae+B1VNw+kIvwDYBqwEBrgfv4vz+O06nC/5jwIM/QM3hg8Krb8SqASk4DSlTaRkzWTGlIjYwEXGGGP8sTsKY4wxfgUtUYjImyKyQ0QWF/O5iMhzIrJKRBaKSI9gxWKMMab0gnlHMR6n9EFxzgXaun9GAy8HMRZjjDGlFLREoarTgT1+NhmEU0ZBVXUmUFtErEPOGGPCjJcFyOI58iWjTe66P70NKyKjce46qF69es/27duHJEBjjDlmORmgCuqD1E0gAkhwz1eEOVt9u1S1QWkOGRGVKlV1HDAOICkpSZOTkz2OyBhT7uVkgS/3z+vXz4DFkwCB5V9DdmqBDytApRrQ4uSghqYJvaDrpQjCpHmb2Jt+kFEDT1lf2uN5mSg245Q9OCTBXWeMMeElbRss+gR8ec7yxlmwvMgiwvlqN4cqcVChElzwHMRWgopVILEfxASv2O+21Czu+3wRA2sKF3WPZ0j/eABGHcMxvUwUk4FbRWQC0AdIdd86NcaUBwczYP1vTpNMoFI+h9U/QkzF4MVVlNQNRa8/8S9Qrd6f18f3gBYnBTemQlSVCbM38q+vlpLj8zGgfdmV/wpaohCRD3EKstV3a+8/iFPMDFV9BZiCUwVzFZABXBOsWIwxIaAKaVuP/OLPPgDfP+h8VtjKqaU/V9eRpd+3tOq0gBNuy1+Orej8CQPrd6czdtIifl+zm36t6vHYkM40rxdombKjC1qiUNURR/lcgVuCdX5jTJBk7YeZL0Nu5pHr57wNmX4edGzSrdByV6hQFc7+V8nOH5cANRuVbJ8ot2xbGos3p/LvizszvFczRMq2szwiOrONMR7IPQgrvoHcLGc5+U3YMi9/GZx290PyDjrTC58/8jgVq0GHQWHzv+9osdxNDkN6JnB2x8b0vqcudapXOvqOpWCJwpjyShV2LgdfDiz5HNZOdx/ddG0sZtylvjdDldpw8l0Qa18hoXYw18eL01bx0k+rqF+jMud3aUKVirFBSxJgicKY8sXnAxTSd8FrA2B/oQcNW/U/cl7VaRqqWNVZV7MxVCq7tm9TMvM27OWvkxayYvsBBneP5/6BHahSMfjDpVuiMKa82DAL3h6Y30R0yNA3nSakhh2gXmtvYjNHtS01i2Gv/k79GpV58+okTmsfun4aSxTGhCtVp0/g4IGjb7v4U6fpyN/z+Vn7nSTR5yaoVheq1oFe1x/Z3GTCzpqdB2jVoAaN46rw/IgenNimHjWrhLa/xxKFMeFm7ruw6jvYngK7V5Zs346D/X9erR6c9aj1LUSA1MwcHvt6KRNmb2TCqL70aVWPczoVNYpu8NlPizHhZP9WmHyrM1//OIhLhNMfgFoB1Mus08J5dNREvO9StnPf54vYmZbN6FNa0bVZbU/jsURhTDiZ8YwzPWUMnHaft7EYT/x14kI+St5I+8Y1ee3KJLokeJskwBKFMd6Y/yEsKDwUNk4/A8CpY0Mbj/HUoSGpRYTOCXHE16nKjae2plKF8BiE1BKFMcGwfYnT10AxY9Iv+woy90Ljzkeub9YXWp5ifQjlyJZ9mfz9s0Vc0LUpF/dI4PK+zb0O6U/sp9GYsrBoInx+M6hbXfRQ+ekqccXv0+0yOO+J4MdmwpLPp7z/xwYe/3oZeT7l7I7edFQHwhKFMSWVkwVzxjslLWIrOWPQpG2HvGznbeVDGneBjhd5FaUJY2t3pfPXSQv5Y+0eTmpTn39f3Jlmdat5HVaxLFEY448vL3/EsJws+PFhmPtO/uet+ju1jOKaQYP2zhNKxhzFyu1pLNu6nyeGduGSngllXsSvrFmiMKYoOZlOH8PXY4r+vFEnGPwqNO4U2rhMxErZsp+UrfsZ2jOBszo25peW9YirFhmFEi1RGAPO3cL6GfkjmH1wSf5ndVo4bzCDc/fQ7TJnpDJjApCdm8cLP67i5Z9W07BmZQa6RfwiJUmAJQpTnmXuhW/uhYzdRQ+iU7Ea3LkUqnr/HLuJTHPWO0X8Vu04wMU94rn//NAU8StrlihM+bQ9BV7ul7/cpCtILJz3JCAQEwONOttjqqbUtqVmMXzc7zSoUZm3runFgOPKbmjSULPfAlM+bfjdmXYaCuc/5RTIM6YMrNqRRpuGNWkcV4UXRvbgxDb1qVE5sr9qIzt6Y4pzMAN2rzpy3Y6lMPMlZ6S19J3OujMftiRhykRqRg6PfpXCJ3M28fEN/ejdsm5YvxtREpYoTPTZMBPePLv4z5t2hzotnbega0bHL7Lx1jeLt3H/F4vZk36Qm/u3pkuCnxctI5AlChN9Jox0pk26OcX1CqrREJr1Dn1MJmqN+WQBn8zZRIcmtXjr6l50io+uJAGWKEw0SNsOO5c5898/5DzFVCUObvjZ07BM9CpYxK97Yh1a1K/O6FNaUTE2PIr4lTVLFCbyZKc57z0c8nS7P28zalro4jHlyqa9Gdz72WIGdW3KkJ4JjOyT6HVIQWeJwkSWFVPhg2F/Xl85DkZ86Mw36mjvPpgy5/Mp781az+NfL0OB8zuXn/4tSxQmvG2cDfs3O/PbFsIvTzvzPa92ymgAxFSADoOccaCNCYLVOw8wdtJCZq/by8lt6/OvweFdxK+sWaIw4WvveufppUOluw859wnoc4M3MZlyac3OdFZsP8BTl3RlSI/4sC/iV9YsUZjwtPYXeHugM3/KGOh4sTNftTbUaupdXKbcWLw5lZSt+xmW1IwzOzRi+j0DiKsaOfWZypIlChNedi6H18+E7FRn+eS74aQ7oFJ1b+My5UZWTh7P/bCSV6evoXGtKlzYtalTxK+cJgmwRGHCSdo2eLHAOw4Dn4Gka7yLx5Q7yev2cM+khazZmc4lPRO4L0KL+JU1SxQmdKb9G/auLf7zhR8500ad4IZfnMJ8xoTIttQsRrw2k0a1qvDOtb05pV0Dr0MKG5YoTPBl7oMPh+cX4qvToujt4ppBq1Ph3CctSZiQWbk9jbaNnCJ+L1/Wk36t61E9wov4lTW7GiZ4cjKdwYA+uzG/CN+dS60z2oSFfRkHeeTLpUyau4mPRvelT6t6nNGhkddhhSVLFCY4tsyDcf2PXHf/LqdyqzEe+3rRVu7/Ygn7Mg5y64A2dG1mL2j6Y4nClL20bflJom5ruPg1qNPckoQJC3d9vIBJczfRKb4Wb1/bi45No6+IX1mzRGHK3qHqrR0ugmFvexuLMRxZxK9n8zq0aViDUSe3pEKUFvEra0G9SiJyjogsF5FVIjK2iM8TRWSaiMwTkYUicl4w4zEhsHMFbJ7jzA95w9tYjAE27sngijf+YNJcpxTMyD6J3NS/tSWJEgjalRKRWOBF4FygAzBCRDoU2uw+4GNV7Q4MB14KVjwmRF7q60z73WrjTRtP5fmUt2as5az/Tmfehr2H7ypMyQXzN7k3sEpV1wCIyARgEJBSYBsFarnzccCWIMZjylrqZlj6P5x/RmDNT05dpoYd4MxHvIzMlHOrdqRxz8SFzN2wj/7HNeCfgzsTX7uq12FFrGAminhgY4HlTUCfQts8BHwrIrcB1YEzijqQiIwGRgMkJkZ/7fewlZsNG/+AzL3w9T2QtrXo7Ya8bu9BGE+t25XBml3p/PfSrlzUrfwV8StrXrcNjADGq+rTItIPeFdEOqmqr+BGqjoOGAeQlJRk949e2LYIXjnpyHU1GkPPq6DvTfnrKlSFilVCG5sxwKJNqSzdup9hvZpxRodG/HLPAGpWsSftykIwE8VmoFmB5QR3XUHXAecAqOrvIlIFqA/sCGJcJlC+PJj1KqRuhJlu91HtRLjoFahY1RmT2u4cjMeycvJ45vuVvPbLGprEVeHCbk4RP0sSZSeYiWI20FZEWuIkiOHAyELbbABOB8aLyPFAFWBnEGMygdq9Gt4dDPvW56/rezOc82/vYjKmkFlrdjP200Ws3ZXOpUnNuPf8462IXxAELVGoaq6I3ApMBWKBN1V1iYg8DCSr6mTgLuA1EbkDp0f0arVHE7z3zb0w88X85b+ut6FFTdjZlprFZa/PokntKrx/fR9ObFPf65CilkTa93JSUpImJyd7HUZ0UoVfnoJp/4KaTaDrcGcsiMo1vY7MmMOWbdtP+8bOw5I/LN1Ov9b1qFbJ6+7W8Ccic1Q1qTT72tU1jp0r4LsHYMXXzvKZD0Pnod7GZEwBe9IP8siXKXw2b/PhIn6nH29F/ELBEoWBidfC4kn5y7cmQ/223sVjTAGqyleLtvLgF0tIzczh/05vS7dEawoNJUsU5ZEvz3kPIms/ZOyC1T866898GHpeA1Vq+d/fmBC66+MFfDpvM10S4nh/VJ/DzU4mdCxRlDepm+H5npCb6SzXbg41m8LQN6D5Cd7GZoyrYBG/Pq3q0r5JTa490Yr4ecUSRXmQlwtvD4R9G2H/pvz1f9tkHdUm7GzYncHYTxdyUfd4hiU149JeVo3Ba5Yool3GHtgy1xmGNL4ntOoP9VrDiX+xl+VMWMnzKeN/W8dTU5cTGyNc3CPB65CMyxJFNJv3HnxxS/5yn5ugyyXexWNMMVZuT2PMxIXM37iP09o35J+DO9Ekzor4hQtLFNHI54PlU+C7B53lpOug9QBoP9DbuIwpxsa9GWzYk8Gzw7txYdemVsQvzFiiiDZbF8IbZ0JulrPcaxSc/5S3MRlThAUb95GydT8jeidyWvtGTL9nADUq21dSOLJ/lWiyZT6MO9WZb9wZBj4DTbt7G5MxhWQezOM/3y3njV/XEl+nKoO7x1OlYqwliTBm/zLRYsoY+GOcM594Alz7tbfxGFOE31fvZuynC1m/O4ORfRIZe257K+IXASxRRLqDGfD+UFg/w1m+5G3oeJG3MRlThK2pmVzxxizi61Tlg1F9OKG1FfGLFJYoIt1vz+UniaunQIsTvY3HmEJStuynQ9NaNImrymtXJtG3VT2qVrK7iEhiiSJS7VgKiz+FNdOc5b9thso1vI3JmAJ2H8jmH/9LYfKCLUwY3Ze+reoxoH1Dr8MypWCJIhIdTIeX+roLAk17WJIwYUNVmbxgC//4XwppWTnccUY7eiTW8ToscwwCShQiUglIVNVVQY7HBGLee860+YlwzRRvYzGmkDs+ms/n87fQrVltnhjahXaNrExMpDtqohCR84H/AJWAliLSDXhQVQcHOzhTiC8PJl4DKV84yxc86208xrh8PkXEKeLXr3U9OsXHcc2JLYmNsRfnokEgdxQPA32AaQCqOl9E2gQ1KnOkX5+B7x88ct3AZ6Ce/TMY763blc7YTxdycfcEhvWyIn7RKJBEkaOq+wq9Uh9Z46dGKlXYuiA/SZx0J1SqDr1H25gRxnO5eT7enLGWp79dQaUKMVzay+4eolUgiWKpiAwDYkSkJXA7MDO4YZVzudlOCY610+Gjy511TbrBGQ/638+YEFm+LY0xExewcFMqZ3ZoxKMXdaJRrSpeh2WCJJBEcSvwAOADPgWmAvcGM6hy7cAOeKrQMKQXvQwdBnkTjzFF2LIvk817M3l+RHcGdmliRfyinBwaSarYDUQuVtVPj7YuVJKSkjQ5OdmLU5e93GxY+wv4cpzlld9B8hvOfKPO0G0EVK0DXUeA/SIaj83bsJelW9MY2cfpg0jPzqW61WeKGCIyR1WTSrNvIP/K9+HcSRT09yLWmZLw+eD9S2Dtz3/+rO8tzvjVsfZLaLyXcTCXp79dwZsz1pJYtxpDesZTuUKsJYlypNh/aRE5GzgHiBeR/xT4qBZOM5Q5Fh9emp8krv8xf7S5Go2hVhPv4jKmgN9W7WLsp4vYsCeDy/sm8tdz2lO5gpXfKG/8/ZdgB7AYyAKWFFifBowNZlBRa8dS2DLPeR9i5bfOuht/dUqCGxNmtqZmcuWbf9CsbjU+Gt2XPq3qeR2S8UixiUJV5wHzROR9Vc0KYUzR6aMrYOnkI9f1ucmShAk7izen0ik+jiZxVXn9KqeIn5UCL98CaWSMF5F/Ah2Aw8+/qWq7oEUVTTb+Ad//A9b/6iyf+bDzBFNMBagV721sxhSwMy2bh/63hK8Wbj1cxK//cVbEzwSWKMYDjwJPAecC12Av3AVmxrPw3QPOfNU6cOUX0KSrtzEZU4iq8vn8zfzjfylkZOdx91nt6NnciviZfIEkimqqOlVEnlLV1cB9IpIM3B/k2CJb2rb8JHH+09Drem/jMaYYt0+Yz/8WbKFHolPEr01DK+JnjhRIosgWkRhgtYjcCGwG7CepOL48SN8Fs151lk9/0JKECTsFi/id3LY+PRJrc2W/FlbEzxQpkERxB1Adp3THP4E44NpgBhWRMvfC7Nfhx0ePXN97lDfxGFOMNTsPMPbTRQzpEc+lvRIZltTM65BMmDtqolDVWe5sGnAFgIhYL2xhCybkJ4kajeDUv0JcAlS2my8THnLzfLz+61r++90KKleIoUpFq/JqAuM3UYhILyAe+FVVd4lIR+CvwGlAQgjiixyb3LIiY9ZAdXve3ISXpVv3c8/EhSzanMrZHRvxyKBONLQifiZA/t7M/jcwBFiA04H9JXAz8DhwY2jCixBZ+2HxRIitZEnChKVtqVlsTc3kpct6cG6nxlbEz5SIvzuKQUBXVc0UkbrARqCzqq4J9OAicg7wLBALvK6qjxWxzTDgIZxHbheo6sgSxO+9mS/DN+6L6g3aexuLMQXMWb+HpVvTuLxvcwa0b8j0ewZQrZLVZzIl5++nJktVMwFUdY+IrChhkogFXgTOBDYBs0VksqqmFNimLfA34ERV3SsikfN2jy8PPhwBK6c6y6c/CCfc7m1MxuBUdX1y6nLe/n0dzetW45KkBCpXiLUkYUrN309OKxE5VCFWcMbLPlwxVlUvPsqxewOrDiUXEZmAc5eSUmCbUcCLqrrXPeaOEsbvnbXTnSTRsCP0vBr6jPY6ImOYvmInf/t0EVtSM7myb3PGWBE/Uwb8JYohhZZfKOGx43Gaqw7ZhDP2dkHtAERkBk7z1EOq+k3hA4nIaGA0QGJiGDypsWIqfDDMmR/4X0gs/NcyJvS27Mvk2vGzSaxXjY9v6EevFnW9DslECX9FAX8I0fnbAv1xnqKaLiKdVXVfoVjGAePAGbgoBHEVLTsN1s2Az25wluOTLEkYzy3alErnhDia1q7KW9f0oleLulbEz5SpYDZabgYKvsmT4K4raBMwS1VzgLUisgInccwOYlyl90RryMt25k/8C5zxkJfRmHJuR1oWD01ewpRF2w4X8Tu5bQOvwzJRKJiJYjbQVkRa4iSI4UDhJ5o+B0YAb4lIfZymqIA7zENi10qY+w7sWpGfJG6YDg072PCkxhOqyqS5m3nkyxQyc/IYc/ZxVsTPBFXAiUJEKqtqdqDbq2quiNwKTMXpf3hTVZeIyMNAsqpOdj87S0RSgDxgjKruLtlfIUj2b4V3B8POpc5yTEVnOmqaVYA1nrr1w3l8tXArSc3r8NiQLrRpWMPrkEyUE1X/Tf4i0ht4A4hT1UQR6Qpcr6q3hSLAwpKSkjQ5OTm4J8lKhccKdJoPfhW6Dg/uOY3xo2ARv4lzNpGencsVfZsTY0X8TIBEZI6qJpVm30DuKJ4DBuI0E6GqC0RkQGlOFvZSN8P0J2HOW85yTAW4dwtUqOxtXKZcW7XjAGMnLWRozwSG905kaE+rnmNCK5BEEaOq6wu98p8XpHi8czADJoyErfOhekNoeDxcMt6ShPFMTp6PcdPX8Oz3K6laKZZqle2FOeONQH7yNrrNT+q+bX0bsCK4YXlgzU9OkgC4fR5UtnZf450lW1IZ88lCUrbu57zOjXnowo40rGlF/Iw3AkkUN+E0PyUC24Hv3XXRxZfrTEf9aEnCeG5nWjY7D2TzyuU9OKdTE6/DMeVcIIkiV1XLT09urDU1GW/MXreHZVv3c0W/FvQ/riHTxwygaiV7cc54L5BEMVtElgMfAZ+qalqQY/LGpvB8x89EvwPZuTzxzTLe+X09LetXZ1ivZlSuEGtJwoSNQEa4ay0iJ+C8MPcPEZkPTFDVCUGPLlS++RvMfMmZr1rb21hMufLzip3c6xbxu+bEFtx91nFWxM+EnZhANlLV31T1dqAHsB94P6hRhVJebn6SuPR9Z/hSY0Jgy75Mrhs/myoVY5h4Yz8evKAj1e3JJhOGjvpTKSI1cMqDDweOB74ATghyXMG3c4VT3G/LXGe5z01w/EBvYzJRT1VZsCmVbs1q07R2VcZf05ukFnWsiJ8Ja4H892Ux8D/gCVX9JcjxhM6LvfLnT38Qeo/yLhZTLuzYn8X9Xyxm6pLth4v4ndS2vtdhGXNUgSSKVqrqC3okobTmJ2dasyn833x7qc4ElaryyZxNPPplCtm5Psae254kK+JnIkixiUJEnlbVu4BJIvKnglABjHAXvqaMcabnPWlJwgTdLR/MZcqibfRuUZfHhnSmVQN7T8dEFn93FB+505KObBfetsyHtG0QW8n6JEzQ5PkUAWJihNPbN6Jf6/pc1jvRiviZiORvhLs/3NnjVfWIZOGWDw/FCHhlK3UzjDvVme99g7exmKi1akca90xcyCVJzRjRO5EhVsTPRLhAHo+9toh115V1IEGXlwv/7eDMJ10HZz3ibTwm6uTk+Xj+h5Wc9+yvrNmVTs0q9qiriQ7++iguxXkktqWIfFrgo5rAvqL3CmO7lufPn/cUxAT0CokxAVm8OZW7P1nAsm1pDOzShIcu7Ej9Gtb/ZaKDv//y/AHsxhnr+sUC69OAecEMKigOFf279D1LEqbM7TqQzd6Mg4y7oidndWzsdTjGlCl/fRRrgbU41WIj37pfnalYkjBlY9aa3SzfnsaVbhG/n8cMsBfnTFTy1/T0s6qeKiJ7gYKPxwqgqlo36NGVpWn/cqbN+ngbh4l4aVk5PP7NMt6buYFW9atzqVvEz5KEiVb+mp4ODXcaHa+OHjwAVetA9ej46xhvTFu2g3s/W8T2/Vlcf1JL7jyrnRXxM1HPX9PTobexmwFbVPWgiJwEdAHewykOGBky9jjTZn29jcNEtC37Mhn1TjKtGlTnpctOoHuivV1tyodAGuw/xxkGtTXwFtAW+CCoUZW1Gc8403ZneRuHiTiqytwNewFoWrsq71zXmy9vO9mShClXAkkUPlXNAS4GnlfVO4D44IZVxhZNdKadh3kbh4ko2/dnMeqdOVz80m/MXLMbgBNa16dSBXsgwpQvAQ2FKiKXAFcAF7nrKgYvpDKWth32b4bKcTYWtgmIqvLR7I38c8pSDub6+Pt5x1sRP1OuBZIorgVuxikzvkZEWgIfBjesMvTbc860V1EvmBvzZze9N5dvlmyjT8u6PD6kCy3qV/c6JGM8Jap/Kgz7541EKgBt3MVVqpob1Kj8SEpK0uTk5MB3eCjOmT6w1160M8UqWMTv07mbyMzJY0QvK+JnooeIzFHVpNLsG8gIdycD7wKbcd6haCwiV6jqjNKcMKQ2z3GmdVtZkjDFWr4tjb9OWsilvZwifhf3sCJ+xhQUSNPTf4HzVDUFQESOx0kcpcpMIbVhljM953Fv4zBh6WCuj5d+WsWL01ZRs0pF4qpGTtebMaEUSKKodChJAKjqUhGpFMSYyoYqTP2bM9+st7exmLCzaJNTxG/59jQGdWvKAwM7UM+K+BlTpEASxVwReQXnJTuAy4iEooBp25xpxepQtba3sZiwszfjIPuzcnjjqiROP76R1+EYE9YCSRQ3ArcD97jLvwDPBy2isuLLcabnPuZtHCZs/LZ6F8u3pXHNiS05pV0Dpt3d3+ozGRMAv4lCRDoDrYHPVPWJ0IRURma+7EwrVPE2DuO5/Vk5/HvKMj78Ywb6CTAAABczSURBVAOtG1RnZJ9EK+JnTAn4qx57L85IdnOBXiLysKq+GbLIjtUOt1vl+Au8jcN46vuU7fz980XsTMtm9CmtuOMMK+JnTEn5u6O4DOiiquki0gCYAkRGolj+Daz5yZmvWNXTUIx3tuzL5Kb359C6QQ3GXZFE12bWV2VMafhLFNmqmg6gqjtFImTEn9xs+PBSZ37wq97GYkLuUBG/ns3rOkX8ru1Dz+Z1rD6TMcfA329PKxH51P3zGdC6wPKnfvY7TETOEZHlIrJKRMb62W6IiKiIHPu7Gd896Ezrtoauw4/5cCZybE3N5Pq3kxny8u+Hi/j1a13PkoQxx8jfHcWQQssvlOTAIhKLM9b2mcAmYLaITC74Toa7XU3g/4BZJTl+sTb87kxH/VAmhzPhz+dTPpy9gX9PWUauz8d95x9PrxaRNQCjMeHM38BFx/pN2xunLtQaABGZAAwCUgpt9wjwODDmGM/n2LUCKtdyRrMz5cKN783h25TtnNC6Ho9d3IXEetW8DsmYqBLIexSlFQ9sLLC8CThiwGoR6QE0U9WvRKTYRCEio4HRAImJif7PWrkmxId/dRFzbHLzfMSIEBMjnNu5Mae1b8ilvZohYkX8jClrnjXeup3j/wHuOtq2qjpOVZNUNalBgwbFb5ibDQe2QzVrdohmS7fu5+KXf+PD2RsAGNw9geG9Ey1JGBMkAd9RiEhlVc0uwbE344y3fUiCu+6QmkAn4Cf3F7wxMFlELlTVEtQRL2DF1FLtZiJDdm4eL05bzUvTVhFXtSL1qod/yTFjokEgZcZ7A28AcUCiiHQFrlfV246y62ygrTvQ0WZgODDy0IeqmgrUL3Cen4C7S50kwLmjADjhaKGZSLNg4z7u/mQBK3cc4OLu8dw/sAN1LFEYExKB3FE8BwwEPgdQ1QUiMuBoO6lqrojcCkwFYoE3VXWJiDwMJKvq5GOI2z+xN2+jTWpmDhkH83jrml4MOK6h1+EYU64EkihiVHV9ofbfvEAOrqpTcN7oLrjugWK27R/IMU358duqXSzblsa1JzlF/H68+1Qrv2GMBwJJFBvd5id13424DVgR3LBMeZaamcO/pyxlwuyNtGlYg8v6OkX8LEkY441AEsVNOM1PicB24Ht3nTFl7tsl27jv88XsOpDNDadaET9jwsFRE4Wq7sDpiA5vvjz49Hpn3h6TjEib92Vyywdzad2gBq9flUSXBCviZ0w4COSpp9cALbxeVUcHJaLSys1yplXioE4LT0MxgVNVZq/bS++WdYmvXZX3rutD90Qr4mdMOAnkt/F74Af3zwygIVCS9ylCY/sSZ9rvVoixpopIsHlfJteMn82wV/OL+PVpZUX8jAk3gTQ9fVRwWUTeBX4NWkSllb3fmcb39DYOc1Q+n/L+rPU89vUyFHjogg5WxM+YMFaaWk8tgfAbjX7tL860ck1v4zBHdcN7c/guZTsnt63PvwZ3plldK+JnTDgLpI9iL/l9FDHAHqDYsSU8M+MZZ9rweG/jMEUqWMRvYJcmnNmhEZf0TLD6TMZEAL+JQpzf4q7k12jyqeqfOrbDRqUadkcRhlK27OeeSQsY3iuRy/s2Z1C3eK9DMsaUgN9EoaoqIlNUtVOoAiqV3audaa/rvI3DHCErJ48XflzFKz+vpna1ijSoWdnrkIwxpRBIH8V8EemuqvOCHk1pPd/DmdY+ylgVJmTmb9zHXR/PZ/XOdIb0SOD+gcdTu5oV8TMmEhWbKESkgqrmAt1xhjFdDaQDgnOz0SNEMfq3elr+fJLdUYSLA1m5ZOX4ePva3pzazs8YIsaYsOfvjuIPoAdwYYhiKZ30nc70qi/tjWyPTV+xkxXb07j+5Fac1La+FfEzJkr4SxQCoKqrQxTLsanV1OsIyq3UjBwe+SqFiXM20a5RDa7o19yK+BkTRfwligYicmdxH6rqf4IQT8kt+8rrCMq1bxZv5f4vlrAn/SA392/N7ae3tQRhTJTxlyhigRq4dxZha+cyZ1rDBrMJtc37Mrntw3m0a1STt67uRaf4OK9DMsYEgb9EsVVVHw5ZJKUlsdB+oL0/ESKqyqy1e+jbqh7xtavywai+dGtWm4qxVp/JmGjl77c7vO8kTMht2pvBVW/NZvi4mYeL+PVqUdeShDFRzt8dxekhi8KENZ9PeXfmeh7/xmnm+8eFHeltRfyMKTeKTRSquieUgZSKLw92LLHxJ4Js9LvJfL90B6e0a8C/BncioY4V8TOmPClN9djwkZPhTCtW8TaOKJST5yPWLeJ3QdemnNupCRf3iLcifsaUQ9HRuNy0u9cRRJXFm1MZ9MIM3p+1HoBB3eIZYpVejSm3IvuOYtNsZ+rL9TaOKJGVk8ezP6xk3PQ11K1eiSZxVb0OyRgTBiI7USz5zJkm9PY2jigwd8Ne7v54AWt2pTMsKYG/n9eBuGoVvQ7LGBMGIjtRbPzDmbY40ds4okDmwTxyfD7eu64PJ7Wt73U4xpgwEtmJonoDOJjhdRQR66flO1i5/QCjTmnFiW3q88Od/alUITq6rYwxZSfyvxVqN/M6goizN/0gd348n6vfms2kuZs4mOsDsCRhjClSZN9RmBJRVb5evI0HvljMvowcbjutDbee1sYShDHGL0sU5cjmfZn834R5tG9ci3eu7UOHprW8DskYEwEsUUQ5VeX31bs5oU19EupUY8LovnRNqE0Fq89kjAmQfVtEsY17MrjijT8Y+fqsw0X8ejava0nCGFMikXtHkZsN636BxBO8jiTs5PmUt39bx5NTlxMbIzx6UScr4meMKbXITRTblzhTq/P0J6PeSebHZTsYcFwD/jm4M01r2xvWxpjSi9xEgTqTPjd6G0aYKFjEb3D3eC7s2pRB3ZpafSZjzDELamO1iJwjIstFZJWIjC3i8ztFJEVEForIDyLSPJjxRKuFm/ZxwfO/8p5bxO+Crk25qLtVejXGlI2gJQoRiQVeBM4FOgAjRKRDoc3mAUmq2gWYCDwRrHiiUVZOHv/+eikXvTiDPekHibcmJmNMEASz6ak3sEpV1wCIyARgEJByaANVnVZg+5nA5QEfPSerbKKMUHPW7+XuTxawdlc6w3s142/nHU9cVSviZ4wpe8FMFPHAxgLLm4A+fra/Dvi6qA9EZDQwGiAxMdFZuXGWM61Q+VjjjEjZOXn4VHn/+j6c2MaK+BljgicsHqgXkcuBJODJoj5X1XGqmqSqSQ0aNHBWVnCfdmrSLTRBhoFpy3bw6s+rATihTX2+v/NUSxLGmKALZqLYDBSs2JfgrjuCiJwB/B24UFWzgxhPxNqTfpC/TJjHNeNn8/n8LYeL+FW0F+eMMSEQzKan2UBbEWmJkyCGAyMLbiAi3YFXgXNUdUcQY4lIqsr/Fm7loclLSMvK4f9Ob8stA6yInzEmtIKWKFQ1V0RuBaYCscCbqrpERB4GklV1Mk5TUw3gE/dRzg2qemGwYoo0m/dlcvfHCzi+SU0eH9qH9o2tiJ8xJvSC+sKdqk4BphRa90CB+TNKffAD2yGmIlSsVvoAw5CqMmPVbk5q6xbxu8Ep4hcbY+9EGGO8EbltGHvXQZ3mUKGS15GUmfW70xn52iwufyO/iF+PxDqWJIwxnorsEh4xERx+AXk+5a0Za3nq2+VUjInhX4M7WxE/Y0zYiI5v2gh33duz+Wn5Tk5v35BHB3eiSZy9YW2MCR+RmyhSvoB6bbyOotQO5vqoEOMU8RvaM+FwIT+rz2SMCTeR20dRrT7ERmb/xPyNThG/d2c6RfwGdmnKoG5WxM8YE54i847iwA7I2AXHD/Q6khLJPJjH098u580Za2lYswqJ9aLriS1jTHSKzESx2q0lWCve2zhKYPa6Pdz18QI27MlgZJ9Exp7bnlpVrIifMSb8RWaiODRoUeeh3oZRAjl5PmJjhA9H9aVf63peh2OMMQGL0EQRGb5P2c6qnQe48dTWnNC6Pt/dcQoVrD6TMSbCROa31tpfvI7Ar90Hsrn9w3lc/04ykwsU8bMkYYyJRJF5R7FxpjOtFl5NOKrK5AVbeGjyEg5k53Lnme248dTWVsTPGBPRIjNRxFSE9gOhSpzXkRxh875MxnyykA5Na/HE0C60a1TT65CMMeaYRWaiEHH+hAGfT/ll1S5ObdeAhDrV+PjGfnSOj7P6TMaYqGFtIsdg7a50Rrw2k6ve/INZbhG/bs2s0qsxJrpE5h2Fx3LzfLzx61r+890KKlWI4YkhXejd0or4GWOikyWKUrj27WSmr9jJmR0a8ehFnWhUq4rXIRljTNBEZqLYkQL1Wof0lNm5eVSMiSEmRhjeqxnDkhI4v3MTq89kjIl6kddHoc47CaTvDtkp527Yy8DnfuWd39cBcF7nJgzsYpVejTHlQwTeUbjlO9qfH/QzZRzM5ampK3jrt7U0qVWFFvWrB/2cxhgTbiIwUYTGH2v3cNcn89m4J5Mr+jbnnnOOo6YV8TPGlEOWKIqR6/NRMSaGj0b3pU+r8HoD3BhjQinyEoUG79BTl2xj1Y4D3DKgDSe0rs+3VsTPGGMisDM7faczrVh240rvTMvmlvfncsO7c/h68VYr4meMMQVE3h3FoVuKbiOP/UiqfDZvMw9/mUJGdh5jzj6O0ae0oqIlCGOMOSzyEkVerjMtgzuKzfsyGTtpEZ0T4nh8SBfaNKxxzMc0xphoE3mJImMXUPovdJ9P+XnlTgYc15CEOtWYeFM/Oja1In7GGFOcyGxjqdG4VLut2XmA4eNmcs1bs5npFvHrkmBF/Iwxxp/Iu6MQge6XlWiX3Dwfr/2ylv9+v4IqFWJ4cmgX+lgRP2OMCUjkJYpSuGb8bH5ZuYtzOjbm4Ys60rCmFfEzxphARW2iyMrJo2JsDLExwsjeiYzsnci5nZt4HZYxxkScyOujUIW8HL+bJK/bw3nP/XK4iN+5nZtYkjDGmFKKzDuKxp2LXJ2encuTU5fz9u/raBpX1R53NcaYMhCZiaLdOX9aNXPNbu76eAFbUjO5ql8Lxpx9HNUrR+ZfzxhjwklUfZNWrRTLJzf0I6mFPdFkjDFlRVSDWGUvCJKaxmrymr1QpRbfLN7K6p3p3DKgDQB5PrV3IowxpggiMkdVk0qzb1A7s0XkHBFZLiKrRGRsEZ9XFpGP3M9niUiLQI6780A2N703hxvfm8vUJdsOF/GzJGGMMWUvaE1PIhILvAicCWwCZovIZFVNKbDZdcBeVW0jIsOBx4FLj3bsC1/4ld25VbjnnOMYdbIV8TPGmGAKZh9Fb2CVqq4BEJEJwCCgYKIYBDzkzk8EXhARUT/tYT5iaNGoLu8N7UnrBvZUkzHGBFswE0U8sLHA8iagT3HbqGquiKQC9YBdBTcSkdHAaHcxe97N/RdPuDkoMUea+hS6VuWYXYt8di3y2bXId1xpd4yIp55UdRwwDkBEkkvbIRNt7Frks2uRz65FPrsW+UQkubT7BrNxfzPQrMBygruuyG1EpAIQB+wOYkzGGGNKKJiJYjbQVkRaikglYDgwudA2k4Gr3PmhwI/++ieMMcaEXtCantw+h1uBqUAs8KaqLhGRh4FkVZ0MvAG8KyKrgD04yeRoxgUr5ghk1yKfXYt8di3y2bXIV+prEXEv3BljjAktewHBGGOMX5YojDHG+BW2iSJY5T8iUQDX4k4RSRGRhSLyg4g09yLOUDjatSiw3RARURGJ2kcjA7kWIjLM/dlYIiIfhDrGUAngdyRRRKaJyDz39+Q8L+IMNhF5U0R2iMjiYj4XEXnOvU4LRaRHQAdW1bD7g9P5vRpoBVQCFgAdCm1zM/CKOz8c+MjruD28FgOAau78TeX5Wrjb1QSmAzOBJK/j9vDnoi0wD6jjLjf0Om4Pr8U44CZ3vgOwzuu4g3QtTgF6AIuL+fw84GtAgL7ArECOG653FIfLf6jqQeBQ+Y+CBgFvu/MTgdNFJBqrAh71WqjqNFXNcBdn4ryzEo0C+bkAeASnblhWKIMLsUCuxSjgRVXdC6CqO0IcY6gEci0UqOXOxwFbQhhfyKjqdJwnSIszCHhHHTOB2iJy1OE/wzVRFFX+I764bVQ1FzhU/iPaBHItCroO538M0eio18K9lW6mql+FMjAPBPJz0Q5oJyIzRGSmiPx5xK/oEMi1eAi4XEQ2AVOA20ITWtgp6fcJECElPExgRORyIAk41etYvCAiMcB/gKs9DiVcVMBpfuqPc5c5XUQ6q+o+T6PyxghgvKo+LSL9cN7f6qSqPq8DiwThekdh5T/yBXItEJEzgL8DF6pqdohiC7WjXYuaQCfgJxFZh9MGOzlKO7QD+bnYBExW1RxVXQuswEkc0SaQa3Ed8DGAqv4OVMEpGFjeBPR9Uli4Jgor/5HvqNdCRLoDr+IkiWhth4ajXAtVTVXV+qraQlVb4PTXXKiqpS6GFsYC+R35HOduAhGpj9MUtSaUQYZIINdiA3A6gIgcj5ModoY0yvAwGbjSffqpL5CqqluPtlNYNj1p8Mp/RJwAr8WTQA3gE7c/f4OqXuhZ0EES4LUoFwK8FlOBs0QkBcgDxqhq1N11B3gt7gJeE5E7cDq2r47G/1iKyIc4/zmo7/bHPAhUBFDVV3D6Z84DVgEZwDUBHTcKr5UxxpgyFK5NT8YYY8KEJQpjjDF+WaIwxhjjlyUKY4wxflmiMMYY45clChN2RCRPROYX+NPCz7YtiquUWcJz/uRWH13glrw4rhTHuFFErnTnrxaRpgU+e11EOpRxnLNFpFsA+/xFRKod67lN+WWJwoSjTFXtVuDPuhCd9zJV7YpTbPLJku6sqq+o6jvu4tVA0wKfXa+qKWUSZX6cLxFYnH8BLFGYUrNEYSKCe+fwi4jMdf+cUMQ2HUXkD/cuZKGItHXXX15g/asiEnuU000H2rj7nu6OYbDIrfVf2V3/mOSPAfKUu+4hEblbRIbi1Nx63z1nVfdOIMm96zj85e7eebxQyjh/p0BBNxF5WUSSxRl74h/uuttxEtY0EZnmrjtLRH53r+MnIlLjKOcx5ZwlChOOqhZodvrMXbcDOFNVewCXAs8Vsd+NwLOq2g3ni3qTW67hUuBEd30ecNlRzn8BsEhEqgDjgUtVtTNOJYObRKQeMBjoqKpdgEcL7qyqE4FknP/5d1PVzAIfT3L3PeRSYEIp4zwHp0zHIX9X1SSgC3CqiHRR1edwSmoPUNUBbimP+4Az3GuZDNx5lPOYci4sS3iYci/T/bIsqCLwgtsmn4dTt6iw34G/i0gC8KmqrhSR04GewGy3vElVnKRTlPdFJBNYh1OG+jhgraqucD9/G7gFeAFnrIs3RORL4MtA/2KqulNE1rh1dlYC7YEZ7nFLEmclnLItBa/TMBEZjfN73QRngJ6Fhfbt666f4Z6nEs51M6ZYlihMpLgD2A50xbkT/tOgRKr6gYjMAs4HpojIDTgjeb2tqn8L4ByXFSwgKCJ1i9rIrS3UG6fI3FDgVuC0EvxdJgDDgGXAZ6qq4nxrBxwnMAenf+J54GIRaQncDfRS1b0iMh6n8F1hAnynqiNKEK8p56zpyUSKOGCrO37AFTjF344gIq2ANW5zyxc4TTA/AENFpKG7TV0JfEzx5UALEWnjLl8B/Oy26cep6hScBNa1iH3TcMqeF+UznJHGRuAkDUoap1vQ7n6gr4i0xxm9LR1IFZFGwLnFxDITOPHQ30lEqotIUXdnxhxmicJEipeAq0RkAU5zTXoR2wwDFovIfJxxKd5xnzS6D/hWRBYC3+E0yxyVqmbhVNf8REQWAT7gFZwv3S/d4/1K0W3844FXDnVmFzruXmAp0FxV/3DXlThOt+/jaZyqsAtwxsdeBnyA05x1yDjgGxGZpqo7cZ7I+tA9z+8419OYYln1WGOMMX7ZHYUxxhi/LFEYY4zxyxKFMcYYvyxRGGOM8csShTHGGL8sURhjjPHLEoUxxhi//h+vIWxS08wLHAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the ROC curve:\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probabilities_one_test)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# < plot the graph >\n",
    "\n",
    "# ROC curve for random model (looks like a straight line)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "\n",
    "# < use the functions plt.xlim() and plt.ylim() to\n",
    "#   set the boundary for the axes from 0 to 1 >\n",
    "\n",
    "# < use the functions plt.xlabel() and plt.ylabel() to\n",
    "#   name the axes \"False Positive Rate\" and \"True Positive Rate\" >\n",
    "\n",
    "# < add the heading \"ROC curve\" with the function plt.title() >\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ROC curve shows how - when tuning classification threshold - it is possible to raise the TPR (measuring how much of all positives - clients at churn risk - we will actually predict), at the expense of raising also the FPR (measuring how much of all the non-churn risk clients we will wrongly suspect for churn). This will allow to clarify with management the priorities (not missing any churn-risk custoemr vs. how much effort to waste by mistake on customers that are not really churn-risk) and maybe adjust classification threshold.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genral conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Project Goal**: Build a model to predict whether a customer will leave the bank soon, based on data on clients’ past behavior and termination of contracts with the bank, with the maximum possible F1 score (at least 0.59, when checked for a test set). Additionally, AUC-ROC metric should be measured and compared with the F1. \n",
    "\n",
    "\n",
    "2. **Data and it's Preparation**: Original data includes 10k entries and 14 columns, only one ('Tenure') with about 9% missing values. No explicit duplicatesData includes:\n",
    "\n",
    "Features:\n",
    "- RowNumber — data string index\n",
    "- CustomerId — unique customer identifier\n",
    "- Surname — surname\n",
    "- CreditScore — credit score\n",
    "- Geography — country of residence\n",
    "- Gender — gender\n",
    "- Age — age\n",
    "- Tenure — period of maturation for a customer’s fixed deposit (years)\n",
    "- Balance — account balance\n",
    "- NumOfProducts — number of banking products used by the customer\n",
    "- HasCrCard — customer has a credit card\n",
    "- IsActiveMember — customer’s activeness\n",
    "- EstimatedSalary — estimated salary\n",
    "\n",
    "Target:\n",
    "- Exited — сustomer has left\n",
    "\n",
    "**Preparing Data**: Following inspection of the data, we performed the following steps\n",
    "\n",
    "    1. Droping the data with missing values on 'Tenure', since it will keep ~91% of the data and it will be complete.\n",
    "    2. Droping the 'RowNumber', 'CustomerId' and 'Surname' columns since they have no real relevance to predicting churn and we dont want them to confuse the model.\n",
    "    3. OHE encoding to the other categorical columns ('Geography' and 'Gender').\n",
    "    4. Splitting the data randomly into 3 sets: training, validation, test (60:20:20).\n",
    "    5. Standardize the numeric features.\n",
    "\n",
    "3. **Class Balance and initial model**: The positive answers (exited) are about a fifth (!) of all the customers. The classes are imbalanced 4:1. Model was trained without taking into account the imbalance. Random forest classifier model produced initial F1 on the validation set (20 trees: F1=0.5911, 100 trees: F1=0.5957). AUC-ROC for test set was 0.837.   \n",
    "\n",
    "4. **Fixing Imbalance**: 2 methods for fixing imbalance were used: class weight adjustment and upsampling. The second one ( together with the first) improved F1 with 20 trees to 0.5988 on the validation set.\n",
    "\n",
    "5. **Model Improvement - tuning hyperparameters**: first, max tree depth was optimized (checked on 20 trees) and depth of 12 was chosen (with 20 trees, on validation set, F1=0.646). Then, it was investigated wether 100 trees will provide a better F1. It did not, and our chosen model is RandomForestClassifier with 20 trees and max tree depth of 12. \n",
    "\n",
    "6. **Additional model training**: Training the final model on the concatenated train+validation set, after upsampling it. \n",
    "\n",
    "6. **Model Testing**: The chosen model was tested on the test set. F1 is 0.60, above the desired threshold. AUC-ROC = 0.846, slight improvement over the 0.837 before the balance and tuning. The ROC curve (above) shows how - when tuning classification threshold - it is possible to raise the TPR (measuring how much of all positives = clietnts at churn risk we will actually predict), at the expense of raising also the FPR (measuring how much of all the non-churn risk clients we will wrongly suspect for churn). This will allow to clarify with management the priorities (not missing any churn-risk custoemr vs. not wasting effort by mistake on customers that are not churn-risk) and maybe adjust classification threshold.    \n",
    "\n",
    "7. **Overall Conclusion**: A model was developed to predict churn, with F1 of 0.60 checked on a test set. Project goal was achieved. Using the ROC curve it is possible to tune the model (tune classification threshold) according to management priorities.  "
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1369,
    "start_time": "2022-03-08T13:28:05.968Z"
   },
   {
    "duration": 38,
    "start_time": "2022-03-08T13:28:08.302Z"
   },
   {
    "duration": 23,
    "start_time": "2022-03-08T13:29:00.424Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-08T13:30:09.187Z"
   },
   {
    "duration": 18,
    "start_time": "2022-03-08T13:42:51.190Z"
   },
   {
    "duration": 367,
    "start_time": "2022-03-08T15:32:59.101Z"
   },
   {
    "duration": 1006,
    "start_time": "2022-03-08T15:33:06.607Z"
   },
   {
    "duration": 30,
    "start_time": "2022-03-08T15:33:07.615Z"
   },
   {
    "duration": 14,
    "start_time": "2022-03-08T15:33:07.647Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-08T15:33:07.663Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-08T15:33:07.672Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-08T15:33:10.674Z"
   },
   {
    "duration": 325,
    "start_time": "2022-03-08T15:52:25.491Z"
   },
   {
    "duration": 285,
    "start_time": "2022-03-08T15:52:33.505Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-08T15:55:26.335Z"
   },
   {
    "duration": 291,
    "start_time": "2022-03-08T15:56:29.044Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-08T15:56:41.366Z"
   },
   {
    "duration": 969,
    "start_time": "2022-03-08T15:57:32.093Z"
   },
   {
    "duration": 27,
    "start_time": "2022-03-08T15:57:33.063Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-08T15:57:33.091Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-08T15:57:33.105Z"
   },
   {
    "duration": 20,
    "start_time": "2022-03-08T15:57:33.113Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-08T15:57:33.135Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-08T15:57:33.145Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-08T15:57:33.160Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-08T15:58:16.601Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-08T16:04:52.535Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-08T16:07:46.576Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-08T16:21:11.726Z"
   },
   {
    "duration": 70,
    "start_time": "2022-03-08T16:23:48.692Z"
   },
   {
    "duration": 34,
    "start_time": "2022-03-08T16:32:14.909Z"
   },
   {
    "duration": 199,
    "start_time": "2022-03-08T16:44:24.481Z"
   },
   {
    "duration": 117,
    "start_time": "2022-03-08T16:44:42.769Z"
   },
   {
    "duration": 536,
    "start_time": "2022-03-08T16:59:03.577Z"
   },
   {
    "duration": 409,
    "start_time": "2022-03-08T16:59:23.062Z"
   },
   {
    "duration": 130,
    "start_time": "2022-03-08T16:59:33.775Z"
   },
   {
    "duration": 558,
    "start_time": "2022-03-08T17:00:52.733Z"
   },
   {
    "duration": 984,
    "start_time": "2022-03-09T01:34:33.087Z"
   },
   {
    "duration": 39,
    "start_time": "2022-03-09T01:34:34.072Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-09T01:34:34.113Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-09T01:34:34.127Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-09T01:34:34.137Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-09T01:34:34.147Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-09T01:34:34.157Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-09T01:34:34.163Z"
   },
   {
    "duration": 61,
    "start_time": "2022-03-09T01:34:34.205Z"
   },
   {
    "duration": 18,
    "start_time": "2022-03-09T01:34:34.268Z"
   },
   {
    "duration": 130,
    "start_time": "2022-03-09T01:34:34.287Z"
   },
   {
    "duration": 150,
    "start_time": "2022-03-09T01:34:34.419Z"
   },
   {
    "duration": 544,
    "start_time": "2022-03-09T01:34:34.571Z"
   },
   {
    "duration": 117,
    "start_time": "2022-03-09T01:36:25.915Z"
   },
   {
    "duration": 644,
    "start_time": "2022-03-09T01:36:29.663Z"
   },
   {
    "duration": 1005,
    "start_time": "2022-03-09T01:36:50.238Z"
   },
   {
    "duration": 28,
    "start_time": "2022-03-09T01:36:51.245Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-09T01:36:51.275Z"
   },
   {
    "duration": 14,
    "start_time": "2022-03-09T01:36:51.288Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-09T01:36:51.303Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-09T01:36:51.320Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-09T01:36:51.331Z"
   },
   {
    "duration": 25,
    "start_time": "2022-03-09T01:36:51.349Z"
   },
   {
    "duration": 67,
    "start_time": "2022-03-09T01:36:51.376Z"
   },
   {
    "duration": 19,
    "start_time": "2022-03-09T01:36:51.445Z"
   },
   {
    "duration": 126,
    "start_time": "2022-03-09T01:36:51.465Z"
   },
   {
    "duration": 149,
    "start_time": "2022-03-09T01:36:51.593Z"
   },
   {
    "duration": 545,
    "start_time": "2022-03-09T01:36:51.744Z"
   },
   {
    "duration": 974,
    "start_time": "2022-03-09T01:38:00.844Z"
   },
   {
    "duration": 28,
    "start_time": "2022-03-09T01:38:01.820Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-09T01:38:01.850Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-09T01:38:01.863Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-09T01:38:01.874Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-09T01:38:01.884Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-09T01:38:01.894Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-09T01:38:01.909Z"
   },
   {
    "duration": 61,
    "start_time": "2022-03-09T01:38:01.927Z"
   },
   {
    "duration": 33,
    "start_time": "2022-03-09T01:38:01.989Z"
   },
   {
    "duration": 139,
    "start_time": "2022-03-09T01:38:02.024Z"
   },
   {
    "duration": 149,
    "start_time": "2022-03-09T01:38:02.165Z"
   },
   {
    "duration": 542,
    "start_time": "2022-03-09T01:38:02.316Z"
   },
   {
    "duration": 962,
    "start_time": "2022-03-09T01:39:05.650Z"
   },
   {
    "duration": 30,
    "start_time": "2022-03-09T01:39:06.614Z"
   },
   {
    "duration": 14,
    "start_time": "2022-03-09T01:39:06.646Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-09T01:39:06.662Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-09T01:39:06.671Z"
   },
   {
    "duration": 23,
    "start_time": "2022-03-09T01:39:06.683Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-09T01:39:06.708Z"
   },
   {
    "duration": 20,
    "start_time": "2022-03-09T01:39:06.715Z"
   },
   {
    "duration": 86,
    "start_time": "2022-03-09T01:39:06.737Z"
   },
   {
    "duration": 22,
    "start_time": "2022-03-09T01:39:06.825Z"
   },
   {
    "duration": 135,
    "start_time": "2022-03-09T01:39:06.848Z"
   },
   {
    "duration": 150,
    "start_time": "2022-03-09T01:39:06.984Z"
   },
   {
    "duration": 538,
    "start_time": "2022-03-09T01:39:07.135Z"
   },
   {
    "duration": 1028,
    "start_time": "2022-03-09T01:40:19.695Z"
   },
   {
    "duration": 29,
    "start_time": "2022-03-09T01:40:20.724Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-09T01:40:20.755Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-09T01:40:20.769Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-09T01:40:20.778Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-09T01:40:20.790Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-09T01:40:20.807Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-09T01:40:20.813Z"
   },
   {
    "duration": 76,
    "start_time": "2022-03-09T01:40:20.830Z"
   },
   {
    "duration": 20,
    "start_time": "2022-03-09T01:40:20.907Z"
   },
   {
    "duration": 130,
    "start_time": "2022-03-09T01:40:20.928Z"
   },
   {
    "duration": 154,
    "start_time": "2022-03-09T01:40:21.060Z"
   },
   {
    "duration": 545,
    "start_time": "2022-03-09T01:40:21.216Z"
   },
   {
    "duration": 113,
    "start_time": "2022-03-09T01:41:28.747Z"
   },
   {
    "duration": 216,
    "start_time": "2022-03-09T01:50:46.425Z"
   },
   {
    "duration": 50,
    "start_time": "2022-03-09T02:08:46.176Z"
   },
   {
    "duration": 68,
    "start_time": "2022-03-09T02:09:55.667Z"
   },
   {
    "duration": 80,
    "start_time": "2022-03-09T02:10:13.509Z"
   },
   {
    "duration": 89,
    "start_time": "2022-03-09T02:10:40.559Z"
   },
   {
    "duration": 3326,
    "start_time": "2022-03-09T02:34:30.042Z"
   },
   {
    "duration": 741,
    "start_time": "2022-03-09T02:37:48.769Z"
   },
   {
    "duration": 302,
    "start_time": "2022-03-09T02:38:36.866Z"
   },
   {
    "duration": 158,
    "start_time": "2022-03-09T02:39:00.374Z"
   },
   {
    "duration": 86,
    "start_time": "2022-03-09T02:39:37.026Z"
   },
   {
    "duration": 182,
    "start_time": "2022-03-09T02:44:50.320Z"
   },
   {
    "duration": 158,
    "start_time": "2022-03-09T02:51:41.064Z"
   },
   {
    "duration": 43,
    "start_time": "2022-03-09T02:53:43.271Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-09T02:54:59.612Z"
   },
   {
    "duration": 160,
    "start_time": "2022-03-09T02:55:22.750Z"
   },
   {
    "duration": 966,
    "start_time": "2022-03-09T02:56:02.681Z"
   },
   {
    "duration": 40,
    "start_time": "2022-03-09T02:56:03.648Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-09T02:56:03.689Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-09T02:56:03.702Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-09T02:56:03.716Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-09T02:56:03.726Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-09T02:56:03.736Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-09T02:56:03.745Z"
   },
   {
    "duration": 76,
    "start_time": "2022-03-09T02:56:03.760Z"
   },
   {
    "duration": 18,
    "start_time": "2022-03-09T02:56:03.838Z"
   },
   {
    "duration": 130,
    "start_time": "2022-03-09T02:56:03.857Z"
   },
   {
    "duration": 151,
    "start_time": "2022-03-09T02:56:03.988Z"
   },
   {
    "duration": 636,
    "start_time": "2022-03-09T02:56:04.141Z"
   },
   {
    "duration": 133,
    "start_time": "2022-03-09T02:56:04.779Z"
   },
   {
    "duration": 262,
    "start_time": "2022-03-09T02:56:04.914Z"
   },
   {
    "duration": 2546,
    "start_time": "2022-03-09T02:56:05.177Z"
   },
   {
    "duration": 853,
    "start_time": "2022-03-09T02:56:07.725Z"
   },
   {
    "duration": 336,
    "start_time": "2022-03-09T02:56:08.580Z"
   },
   {
    "duration": 96,
    "start_time": "2022-03-09T02:56:08.918Z"
   },
   {
    "duration": 174,
    "start_time": "2022-03-09T02:56:09.016Z"
   },
   {
    "duration": 172,
    "start_time": "2022-03-09T02:56:09.192Z"
   },
   {
    "duration": 807,
    "start_time": "2022-03-09T04:20:03.459Z"
   },
   {
    "duration": 161,
    "start_time": "2022-03-09T04:20:20.972Z"
   },
   {
    "duration": 1106,
    "start_time": "2022-03-09T07:10:36.843Z"
   },
   {
    "duration": 31,
    "start_time": "2022-03-09T07:10:37.951Z"
   },
   {
    "duration": 21,
    "start_time": "2022-03-09T07:10:37.985Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-09T07:10:38.008Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-09T07:10:38.020Z"
   },
   {
    "duration": 18,
    "start_time": "2022-03-09T07:10:38.034Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-09T07:10:38.053Z"
   },
   {
    "duration": 48,
    "start_time": "2022-03-09T07:10:38.064Z"
   },
   {
    "duration": 87,
    "start_time": "2022-03-09T07:10:38.114Z"
   },
   {
    "duration": 26,
    "start_time": "2022-03-09T07:10:38.203Z"
   },
   {
    "duration": 172,
    "start_time": "2022-03-09T07:10:38.231Z"
   },
   {
    "duration": 183,
    "start_time": "2022-03-09T07:10:38.405Z"
   },
   {
    "duration": 657,
    "start_time": "2022-03-09T07:10:38.590Z"
   },
   {
    "duration": 143,
    "start_time": "2022-03-09T07:10:39.249Z"
   },
   {
    "duration": 279,
    "start_time": "2022-03-09T07:10:39.394Z"
   },
   {
    "duration": 2856,
    "start_time": "2022-03-09T07:10:39.674Z"
   },
   {
    "duration": 939,
    "start_time": "2022-03-09T07:10:42.532Z"
   },
   {
    "duration": 395,
    "start_time": "2022-03-09T07:10:43.473Z"
   },
   {
    "duration": 120,
    "start_time": "2022-03-09T07:10:43.870Z"
   },
   {
    "duration": 202,
    "start_time": "2022-03-09T07:10:43.992Z"
   },
   {
    "duration": 207,
    "start_time": "2022-03-09T07:10:44.200Z"
   },
   {
    "duration": 200,
    "start_time": "2022-03-09T07:10:44.409Z"
   },
   {
    "duration": 1072,
    "start_time": "2022-03-09T07:11:09.447Z"
   },
   {
    "duration": 25,
    "start_time": "2022-03-09T07:11:10.521Z"
   },
   {
    "duration": 18,
    "start_time": "2022-03-09T07:11:10.549Z"
   },
   {
    "duration": 29,
    "start_time": "2022-03-09T07:11:10.569Z"
   },
   {
    "duration": 34,
    "start_time": "2022-03-09T07:11:10.600Z"
   },
   {
    "duration": 25,
    "start_time": "2022-03-09T07:11:10.636Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-09T07:11:10.663Z"
   },
   {
    "duration": 34,
    "start_time": "2022-03-09T07:11:10.674Z"
   },
   {
    "duration": 78,
    "start_time": "2022-03-09T07:11:10.710Z"
   },
   {
    "duration": 34,
    "start_time": "2022-03-09T07:11:10.790Z"
   },
   {
    "duration": 157,
    "start_time": "2022-03-09T07:11:10.825Z"
   },
   {
    "duration": 192,
    "start_time": "2022-03-09T07:11:10.984Z"
   },
   {
    "duration": 708,
    "start_time": "2022-03-09T07:11:11.178Z"
   },
   {
    "duration": 168,
    "start_time": "2022-03-09T07:11:11.888Z"
   },
   {
    "duration": 293,
    "start_time": "2022-03-09T07:11:12.058Z"
   },
   {
    "duration": 2857,
    "start_time": "2022-03-09T07:11:12.353Z"
   },
   {
    "duration": 1044,
    "start_time": "2022-03-09T07:11:15.212Z"
   },
   {
    "duration": 487,
    "start_time": "2022-03-09T07:11:16.258Z"
   },
   {
    "duration": 122,
    "start_time": "2022-03-09T07:11:16.746Z"
   },
   {
    "duration": 212,
    "start_time": "2022-03-09T07:11:16.871Z"
   },
   {
    "duration": 209,
    "start_time": "2022-03-09T07:11:17.085Z"
   },
   {
    "duration": 211,
    "start_time": "2022-03-09T07:11:17.297Z"
   },
   {
    "duration": 174,
    "start_time": "2022-03-09T07:15:54.541Z"
   },
   {
    "duration": 1106,
    "start_time": "2022-03-09T07:45:30.218Z"
   },
   {
    "duration": 27,
    "start_time": "2022-03-09T07:45:31.326Z"
   },
   {
    "duration": 18,
    "start_time": "2022-03-09T07:45:31.355Z"
   },
   {
    "duration": 27,
    "start_time": "2022-03-09T07:45:31.375Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-09T07:45:31.405Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-09T07:45:31.421Z"
   },
   {
    "duration": 17,
    "start_time": "2022-03-09T07:45:31.436Z"
   },
   {
    "duration": 47,
    "start_time": "2022-03-09T07:45:31.456Z"
   },
   {
    "duration": 76,
    "start_time": "2022-03-09T07:45:31.505Z"
   },
   {
    "duration": 34,
    "start_time": "2022-03-09T07:45:31.583Z"
   },
   {
    "duration": 170,
    "start_time": "2022-03-09T07:45:31.619Z"
   },
   {
    "duration": 192,
    "start_time": "2022-03-09T07:45:31.791Z"
   },
   {
    "duration": 677,
    "start_time": "2022-03-09T07:49:16.043Z"
   },
   {
    "duration": 146,
    "start_time": "2022-03-09T07:54:42.557Z"
   },
   {
    "duration": 277,
    "start_time": "2022-03-09T07:59:18.847Z"
   },
   {
    "duration": 2860,
    "start_time": "2022-03-09T08:02:11.579Z"
   },
   {
    "duration": 1103,
    "start_time": "2022-03-09T08:05:08.076Z"
   },
   {
    "duration": 469,
    "start_time": "2022-03-09T08:08:11.608Z"
   },
   {
    "duration": 119,
    "start_time": "2022-03-09T08:10:09.556Z"
   },
   {
    "duration": 240,
    "start_time": "2022-03-09T08:12:03.070Z"
   },
   {
    "duration": 243,
    "start_time": "2022-03-09T08:13:03.308Z"
   },
   {
    "duration": 251,
    "start_time": "2022-03-09T08:13:43.264Z"
   },
   {
    "duration": 240,
    "start_time": "2022-03-09T08:13:52.741Z"
   },
   {
    "duration": 232,
    "start_time": "2022-03-09T08:24:41.230Z"
   },
   {
    "duration": 180,
    "start_time": "2022-03-09T08:27:29.227Z"
   },
   {
    "duration": 1341,
    "start_time": "2022-03-10T14:42:06.144Z"
   },
   {
    "duration": 30,
    "start_time": "2022-03-10T14:42:07.488Z"
   },
   {
    "duration": 35,
    "start_time": "2022-03-10T14:42:07.521Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-10T14:42:07.558Z"
   },
   {
    "duration": 38,
    "start_time": "2022-03-10T14:42:07.573Z"
   },
   {
    "duration": 33,
    "start_time": "2022-03-10T14:42:07.614Z"
   },
   {
    "duration": 24,
    "start_time": "2022-03-10T14:42:07.650Z"
   },
   {
    "duration": 52,
    "start_time": "2022-03-10T14:42:07.677Z"
   },
   {
    "duration": 97,
    "start_time": "2022-03-10T14:42:53.172Z"
   },
   {
    "duration": 48,
    "start_time": "2022-03-10T14:43:03.455Z"
   },
   {
    "duration": 224,
    "start_time": "2022-03-10T14:48:58.651Z"
   },
   {
    "duration": 234,
    "start_time": "2022-03-10T14:49:13.325Z"
   },
   {
    "duration": 885,
    "start_time": "2022-03-10T14:50:46.044Z"
   },
   {
    "duration": 880,
    "start_time": "2022-03-10T14:56:46.779Z"
   },
   {
    "duration": 984,
    "start_time": "2022-03-10T14:58:05.543Z"
   },
   {
    "duration": 257,
    "start_time": "2022-03-10T14:58:35.893Z"
   },
   {
    "duration": 410,
    "start_time": "2022-03-10T15:00:34.300Z"
   },
   {
    "duration": 1309,
    "start_time": "2022-03-10T15:02:35.603Z"
   },
   {
    "duration": 47,
    "start_time": "2022-03-10T15:02:36.915Z"
   },
   {
    "duration": 33,
    "start_time": "2022-03-10T15:02:36.965Z"
   },
   {
    "duration": 17,
    "start_time": "2022-03-10T15:02:37.001Z"
   },
   {
    "duration": 46,
    "start_time": "2022-03-10T15:02:37.021Z"
   },
   {
    "duration": 23,
    "start_time": "2022-03-10T15:02:37.070Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-10T15:02:37.095Z"
   },
   {
    "duration": 61,
    "start_time": "2022-03-10T15:02:37.106Z"
   },
   {
    "duration": 119,
    "start_time": "2022-03-10T15:02:37.170Z"
   },
   {
    "duration": 60,
    "start_time": "2022-03-10T15:02:37.291Z"
   },
   {
    "duration": 230,
    "start_time": "2022-03-10T15:02:37.353Z"
   },
   {
    "duration": 240,
    "start_time": "2022-03-10T15:02:37.586Z"
   },
   {
    "duration": 906,
    "start_time": "2022-03-10T15:02:37.829Z"
   },
   {
    "duration": 938,
    "start_time": "2022-03-10T15:02:38.738Z"
   },
   {
    "duration": 202,
    "start_time": "2022-03-10T15:02:39.679Z"
   },
   {
    "duration": 471,
    "start_time": "2022-03-10T15:02:39.884Z"
   },
   {
    "duration": 1316,
    "start_time": "2022-03-10T15:04:10.037Z"
   },
   {
    "duration": 31,
    "start_time": "2022-03-10T15:04:11.356Z"
   },
   {
    "duration": 21,
    "start_time": "2022-03-10T15:04:11.390Z"
   },
   {
    "duration": 28,
    "start_time": "2022-03-10T15:04:11.413Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-10T15:04:11.443Z"
   },
   {
    "duration": 17,
    "start_time": "2022-03-10T15:04:11.461Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-10T15:04:11.481Z"
   },
   {
    "duration": 28,
    "start_time": "2022-03-10T15:04:11.807Z"
   },
   {
    "duration": 90,
    "start_time": "2022-03-10T15:04:11.838Z"
   },
   {
    "duration": 49,
    "start_time": "2022-03-10T15:04:21.936Z"
   },
   {
    "duration": 215,
    "start_time": "2022-03-10T15:04:34.577Z"
   },
   {
    "duration": 234,
    "start_time": "2022-03-10T15:04:46.617Z"
   },
   {
    "duration": 877,
    "start_time": "2022-03-10T15:05:09.577Z"
   },
   {
    "duration": 1152,
    "start_time": "2022-03-10T22:05:36.401Z"
   },
   {
    "duration": 31,
    "start_time": "2022-03-10T22:05:37.555Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-10T22:05:37.588Z"
   },
   {
    "duration": 14,
    "start_time": "2022-03-10T22:05:37.606Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-10T22:05:37.622Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-10T22:05:37.640Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-10T22:05:37.677Z"
   },
   {
    "duration": 26,
    "start_time": "2022-03-10T22:05:37.685Z"
   },
   {
    "duration": 85,
    "start_time": "2022-03-10T22:05:37.713Z"
   },
   {
    "duration": 34,
    "start_time": "2022-03-10T22:05:54.183Z"
   },
   {
    "duration": 157,
    "start_time": "2022-03-10T22:06:20.956Z"
   },
   {
    "duration": 181,
    "start_time": "2022-03-10T22:08:07.080Z"
   },
   {
    "duration": 676,
    "start_time": "2022-03-10T22:08:38.370Z"
   },
   {
    "duration": 665,
    "start_time": "2022-03-10T22:10:11.497Z"
   },
   {
    "duration": 140,
    "start_time": "2022-03-10T22:11:10.150Z"
   },
   {
    "duration": 138,
    "start_time": "2022-03-10T22:14:27.081Z"
   },
   {
    "duration": 141,
    "start_time": "2022-03-10T22:14:34.983Z"
   },
   {
    "duration": 359,
    "start_time": "2022-03-10T22:15:02.467Z"
   },
   {
    "duration": 219,
    "start_time": "2022-03-10T22:15:35.170Z"
   },
   {
    "duration": 282,
    "start_time": "2022-03-10T22:15:49.875Z"
   },
   {
    "duration": 279,
    "start_time": "2022-03-10T22:17:40.983Z"
   },
   {
    "duration": 274,
    "start_time": "2022-03-10T22:18:24.142Z"
   },
   {
    "duration": 2726,
    "start_time": "2022-03-10T22:23:22.822Z"
   },
   {
    "duration": 2757,
    "start_time": "2022-03-10T22:24:20.304Z"
   },
   {
    "duration": 2738,
    "start_time": "2022-03-10T22:24:40.853Z"
   },
   {
    "duration": 2810,
    "start_time": "2022-03-10T22:25:30.413Z"
   },
   {
    "duration": 2846,
    "start_time": "2022-03-10T22:27:00.518Z"
   },
   {
    "duration": 2794,
    "start_time": "2022-03-10T22:31:08.163Z"
   },
   {
    "duration": 988,
    "start_time": "2022-03-10T22:34:32.271Z"
   },
   {
    "duration": 2793,
    "start_time": "2022-03-10T22:34:42.716Z"
   },
   {
    "duration": 986,
    "start_time": "2022-03-10T22:35:06.103Z"
   },
   {
    "duration": 13112,
    "start_time": "2022-03-10T22:35:57.706Z"
   },
   {
    "duration": 468,
    "start_time": "2022-03-10T22:43:01.530Z"
   },
   {
    "duration": 124,
    "start_time": "2022-03-10T22:43:15.068Z"
   },
   {
    "duration": 5326,
    "start_time": "2022-03-10T22:43:50.871Z"
   },
   {
    "duration": 7919,
    "start_time": "2022-03-10T22:44:14.367Z"
   },
   {
    "duration": 10474,
    "start_time": "2022-03-10T22:44:31.527Z"
   },
   {
    "duration": 230,
    "start_time": "2022-03-10T22:45:31.905Z"
   },
   {
    "duration": 220,
    "start_time": "2022-03-10T22:45:43.762Z"
   },
   {
    "duration": 1098,
    "start_time": "2022-03-10T22:46:49.181Z"
   },
   {
    "duration": 1076,
    "start_time": "2022-03-10T22:49:52.297Z"
   },
   {
    "duration": 1082,
    "start_time": "2022-03-10T22:50:03.722Z"
   },
   {
    "duration": 1071,
    "start_time": "2022-03-10T22:51:21.362Z"
   },
   {
    "duration": 30,
    "start_time": "2022-03-10T22:51:22.435Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-10T22:51:22.467Z"
   },
   {
    "duration": 22,
    "start_time": "2022-03-10T22:51:22.484Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-10T22:51:22.508Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-10T22:51:22.522Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-10T22:51:22.536Z"
   },
   {
    "duration": 35,
    "start_time": "2022-03-10T22:51:22.542Z"
   },
   {
    "duration": 68,
    "start_time": "2022-03-10T22:51:22.580Z"
   },
   {
    "duration": 50,
    "start_time": "2022-03-10T22:51:22.650Z"
   },
   {
    "duration": 175,
    "start_time": "2022-03-10T22:51:22.702Z"
   },
   {
    "duration": 180,
    "start_time": "2022-03-10T22:51:22.878Z"
   },
   {
    "duration": 660,
    "start_time": "2022-03-10T22:51:23.059Z"
   },
   {
    "duration": 676,
    "start_time": "2022-03-10T22:51:23.720Z"
   },
   {
    "duration": 144,
    "start_time": "2022-03-10T22:51:24.398Z"
   },
   {
    "duration": 272,
    "start_time": "2022-03-10T22:51:24.544Z"
   },
   {
    "duration": 2775,
    "start_time": "2022-03-10T22:51:24.818Z"
   },
   {
    "duration": 2840,
    "start_time": "2022-03-10T22:51:27.595Z"
   },
   {
    "duration": 1039,
    "start_time": "2022-03-10T22:51:30.437Z"
   },
   {
    "duration": 13084,
    "start_time": "2022-03-10T22:51:31.478Z"
   },
   {
    "duration": 1087,
    "start_time": "2022-03-10T22:51:44.564Z"
   },
   {
    "duration": 1138,
    "start_time": "2022-03-10T22:51:45.653Z"
   },
   {
    "duration": 1092,
    "start_time": "2022-03-10T22:55:34.768Z"
   },
   {
    "duration": 208,
    "start_time": "2022-03-10T22:56:39.708Z"
   },
   {
    "duration": 204,
    "start_time": "2022-03-10T23:03:28.686Z"
   },
   {
    "duration": 215,
    "start_time": "2022-03-10T23:04:48.893Z"
   },
   {
    "duration": 234,
    "start_time": "2022-03-10T23:05:00.606Z"
   },
   {
    "duration": 219,
    "start_time": "2022-03-10T23:06:20.697Z"
   },
   {
    "duration": 207,
    "start_time": "2022-03-10T23:07:44.723Z"
   },
   {
    "duration": 650,
    "start_time": "2022-03-10T23:10:19.012Z"
   },
   {
    "duration": 648,
    "start_time": "2022-03-10T23:10:22.872Z"
   },
   {
    "duration": 141,
    "start_time": "2022-03-10T23:11:30.419Z"
   },
   {
    "duration": 280,
    "start_time": "2022-03-10T23:12:02.139Z"
   },
   {
    "duration": 213,
    "start_time": "2022-03-10T23:12:17.588Z"
   },
   {
    "duration": 183,
    "start_time": "2022-03-10T23:16:29.435Z"
   },
   {
    "duration": 1362,
    "start_time": "2022-03-11T12:50:33.593Z"
   },
   {
    "duration": 32,
    "start_time": "2022-03-11T12:50:34.958Z"
   },
   {
    "duration": 25,
    "start_time": "2022-03-11T12:50:34.994Z"
   },
   {
    "duration": 14,
    "start_time": "2022-03-11T12:50:35.022Z"
   },
   {
    "duration": 45,
    "start_time": "2022-03-11T12:50:35.039Z"
   },
   {
    "duration": 17,
    "start_time": "2022-03-11T12:50:35.086Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-11T12:50:35.107Z"
   },
   {
    "duration": 70,
    "start_time": "2022-03-11T12:50:35.120Z"
   },
   {
    "duration": 642,
    "start_time": "2022-03-11T12:50:35.193Z"
   },
   {
    "duration": 1410,
    "start_time": "2022-03-11T12:54:51.493Z"
   },
   {
    "duration": 36,
    "start_time": "2022-03-11T12:54:52.906Z"
   },
   {
    "duration": 29,
    "start_time": "2022-03-11T12:54:52.946Z"
   },
   {
    "duration": 17,
    "start_time": "2022-03-11T12:54:52.979Z"
   },
   {
    "duration": 23,
    "start_time": "2022-03-11T12:54:52.999Z"
   },
   {
    "duration": 59,
    "start_time": "2022-03-11T12:54:53.025Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-11T12:54:53.087Z"
   },
   {
    "duration": 30,
    "start_time": "2022-03-11T12:54:53.099Z"
   },
   {
    "duration": 147,
    "start_time": "2022-03-11T12:54:53.132Z"
   },
   {
    "duration": 48,
    "start_time": "2022-03-11T12:55:16.371Z"
   },
   {
    "duration": 268,
    "start_time": "2022-03-11T13:00:16.733Z"
   },
   {
    "duration": 252,
    "start_time": "2022-03-11T13:01:04.323Z"
   },
   {
    "duration": 951,
    "start_time": "2022-03-11T13:03:21.626Z"
   },
   {
    "duration": 994,
    "start_time": "2022-03-11T13:05:23.789Z"
   },
   {
    "duration": 199,
    "start_time": "2022-03-11T13:25:19.822Z"
   },
   {
    "duration": 196,
    "start_time": "2022-03-11T13:26:06.425Z"
   },
   {
    "duration": 328,
    "start_time": "2022-03-11T13:26:32.816Z"
   },
   {
    "duration": 430,
    "start_time": "2022-03-11T13:26:41.522Z"
   },
   {
    "duration": 696,
    "start_time": "2022-03-11T13:27:15.120Z"
   },
   {
    "duration": 698,
    "start_time": "2022-03-11T13:27:27.806Z"
   },
   {
    "duration": 424,
    "start_time": "2022-03-11T13:28:23.516Z"
   },
   {
    "duration": 392,
    "start_time": "2022-03-11T13:28:34.802Z"
   },
   {
    "duration": 299,
    "start_time": "2022-03-11T13:28:46.805Z"
   },
   {
    "duration": 248,
    "start_time": "2022-03-11T13:28:58.260Z"
   },
   {
    "duration": 360,
    "start_time": "2022-03-11T13:29:05.389Z"
   },
   {
    "duration": 469,
    "start_time": "2022-03-11T13:29:18.763Z"
   },
   {
    "duration": 332,
    "start_time": "2022-03-11T13:29:25.059Z"
   },
   {
    "duration": 297,
    "start_time": "2022-03-11T13:31:04.595Z"
   },
   {
    "duration": 2944,
    "start_time": "2022-03-11T13:45:09.152Z"
   },
   {
    "duration": 3086,
    "start_time": "2022-03-11T13:46:42.944Z"
   },
   {
    "duration": 1342,
    "start_time": "2022-03-11T13:52:17.493Z"
   },
   {
    "duration": 255,
    "start_time": "2022-03-11T13:52:46.430Z"
   },
   {
    "duration": 1227,
    "start_time": "2022-03-11T13:52:53.371Z"
   },
   {
    "duration": 14469,
    "start_time": "2022-03-11T13:53:58.312Z"
   },
   {
    "duration": 1163,
    "start_time": "2022-03-11T13:57:09.618Z"
   },
   {
    "duration": 1197,
    "start_time": "2022-03-11T13:57:20.187Z"
   },
   {
    "duration": 255,
    "start_time": "2022-03-11T13:57:32.068Z"
   },
   {
    "duration": 250,
    "start_time": "2022-03-11T13:57:38.559Z"
   },
   {
    "duration": 255,
    "start_time": "2022-03-11T13:58:22.279Z"
   },
   {
    "duration": 380,
    "start_time": "2022-03-11T14:36:17.970Z"
   },
   {
    "duration": 336,
    "start_time": "2022-03-11T14:36:25.421Z"
   },
   {
    "duration": 332,
    "start_time": "2022-03-11T14:37:19.612Z"
   },
   {
    "duration": 335,
    "start_time": "2022-03-11T14:44:23.454Z"
   },
   {
    "duration": 273,
    "start_time": "2022-03-11T14:55:05.825Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
