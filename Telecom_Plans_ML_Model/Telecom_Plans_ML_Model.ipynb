{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML model - Ultra or Smart ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mobile carrier Megaline has found out that many of our subscribers use legacy plans. Management wants to develop a model that would analyze subscribers' behavior and recommend one of Megaline's newer plans: Smart or Ultra.\n",
    "We have access to behavior data about subscribers who have already switched to the new plans. For this classification task, we need to develop a model that will pick the right plan. Since we’ve already performed the data preprocessing step, we can move straight to creating the model.\n",
    "\n",
    "**Project Goal**: \n",
    "\n",
    "\n",
    "**Develop a model** that will recommend the right plan (Ultra or Smart), based on behavior data about subscribers who have already switched to the new plans, **with the highest possible accuracy**. Managemnt defined that the **threshold for accuracy is 0.75** (checked on a test set that was not used at all for training). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading libraries\n",
    "from scipy import stats as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data into a DataFrame: \n",
    "df = pd.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking through the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null float64\n",
      "minutes     3214 non-null float64\n",
      "messages    3214 non-null float64\n",
      "mb_used     3214 non-null float64\n",
      "is_ultra    3214 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for explicit duplicates: \n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every observation in the dataset contains monthly behavior information about one user. We can see we have full 3214 entries (no missing values, no explicit duplicates, and datatypes are ok). The information given is as follows:\n",
    "- сalls — number of calls,\n",
    "- minutes — total call duration in minutes,\n",
    "- messages — number of text messages,\n",
    "- mb_used — Internet traffic used in MB,\n",
    "- is_ultra — plan for the current month (Ultra - 1, Smart - 0).\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training, validation, and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have only these 3214 entries of data, so we will split it into 3 sets: training set (60% of the data), validation set (20%) and test set (20%). We will later use the training set and validation set to train and investigate different models, and after choosing our best accuracy model (as asked by management) - we will check it's accuracy using the test set. In order to create random splits - we will use the function 'train_test_split' (twice, because it splits randomly into 2 sets). \n",
    "\n",
    "For convenience we will symbol 'features' as 'X', and 'target' as 'y'. For the features of each set we will drop the 'is_ultra' column, and it will be the target of each set. We will check the sizes ('shape') of the 3 sets after the splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (1928, 4)\n",
      "Training target shape: (1928,)\n",
      "Validation features shape: (643, 4)\n",
      "Validation target shape: (643,)\n",
      "Test features shape: (643, 4)\n",
      "Test target shape: (643,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data into 3 sets, and check their sizes('shape'):   \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We want to split the data in 60:20:20 for train:valid:test dataset\n",
    "train_size=0.6\n",
    "\n",
    "# For convenience we will symbol 'features' as 'X', and 'target' as 'y'\n",
    "X = df.drop(['is_ultra'], axis=1)\n",
    "y = df['is_ultra']\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.6)\n",
    "\n",
    "# Now since we want the valid and test size to be equal (20% each of overall data). \n",
    "# we have to define valid_size=0.5 (that is 50% of remaining data)\n",
    "test_size = 0.5\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)\n",
    "\n",
    "print('Training features shape:', X_train.shape), print('Training target shape:', y_train.shape)\n",
    "print('Validation features shape:', X_valid.shape), print('Validation target shape:', y_valid.shape)\n",
    "print('Test features shape:', X_test.shape), print('Test target shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3 data sets sizes ('shape') are as expected: 643 (20%) entries for the validation and the test sets, and 1928 (60%) entries for the training set. Features have 4 columns after the 'is_ultra' was drop.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training different models and investigating their accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train different models of 3 kinds that are used for classification: decision tree, random forest, and logistic regression. In eah kind - we will try to improve accuracy by changing hyperparameters. We will not use the test set at all at this stage, but use each time the vaidation set to investigate the accuracy of each model with the specific hyperparameters. In order to make our comparisments more reliable - we will keep random_state in all investigations on the same number (12345).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameter we will change will be the tree depth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Training set: 0.808091286307054\n",
      "Validation set: 0.7744945567651633\n"
     ]
    }
   ],
   "source": [
    "# Decision tree with depth of 3:\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define the model\n",
    "model = DecisionTreeClassifier(random_state=12345, max_depth=3)\n",
    "\n",
    "# Train the model on the training set:\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Investigate model accuracy for training and validation sets: \n",
    "train_predictions = model.predict(X_train) \n",
    "valid_predictions = model.predict(X_valid) \n",
    "\n",
    "print('Accuracy')\n",
    "print('Training set:', accuracy_score(y_train, train_predictions)) \n",
    "print('Validation set:', accuracy_score(y_valid, valid_predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree depth of 3 gave us already 77.45% accuracy on the validation set, which is above the defined threshold, but we were asked to develop the highest possible accuracy, so we will try with  ahigher depth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Training set: 0.8112033195020747\n",
      "Validation set: 0.7776049766718507\n"
     ]
    }
   ],
   "source": [
    "# Decision tree with depth of 4:\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define the model\n",
    "model = DecisionTreeClassifier(random_state=12345, max_depth=4)\n",
    "\n",
    "# Train the model on the training set:\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Investigate model accuracy for training and validation sets: \n",
    "train_predictions = model.predict(X_train) \n",
    "valid_predictions = model.predict(X_valid) \n",
    "\n",
    "print('Accuracy')\n",
    "print('Training set:', accuracy_score(y_train, train_predictions)) \n",
    "print('Validation set:', accuracy_score(y_valid, valid_predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree depth of 4 gave us slightly higher accuracy on the validation set (77.76%), let's try to raise the depth once more: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Training set: 0.8241701244813278\n",
      "Validation set: 0.7713841368584758\n"
     ]
    }
   ],
   "source": [
    "# Decision tree with depth of 5:\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define the model\n",
    "model = DecisionTreeClassifier(random_state=12345, max_depth=5)\n",
    "\n",
    "# Train the model on the training set:\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Investigate model accuracy for training and validation sets: \n",
    "train_predictions = model.predict(X_train) \n",
    "valid_predictions = model.predict(X_valid) \n",
    "\n",
    "print('Accuracy')\n",
    "print('Training set:', accuracy_score(y_train, train_predictions)) \n",
    "print('Validation set:', accuracy_score(y_valid, valid_predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree depth of 5 kept raising the accuracy on the training set (3: 80.81%, 4: 81.12%, 5: 82.42%) BUT the accuracy on the validation set - the important one - got lower (only 77.14%). This is clear overfitting. So for now our best accuracy on validation set is 77.76%. Let's try other kinds of models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendom Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameter we will change will be the number of trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Training set: 0.9771784232365145\n",
      "Validation set: 0.7791601866251944\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with 10 trees: \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestClassifier(random_state=12345, n_estimators=10) \n",
    "\n",
    "# Train the model on the training set:\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Investigate model accuracy for training and validation sets: \n",
    "train_predictions = model.predict(X_train) \n",
    "valid_predictions = model.predict(X_valid) \n",
    "\n",
    "print('Accuracy')\n",
    "print('Training set:', accuracy_score(y_train, train_predictions)) \n",
    "print('Validation set:', accuracy_score(y_valid, valid_predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 trees gave us already 77.92% accuracy on the validation set, which is above the defined threshold and higher than our best accuracy decision tree model, but we were asked to develop the highest possible accuracy, so we will try with more trees (altough there is a tradeoff with speed, but we are committed to the current project definition of best accuracy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Training set: 0.9963692946058091\n",
      "Validation set: 0.7884914463452566\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with 30 trees: \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestClassifier(random_state=12345, n_estimators=30) \n",
    "\n",
    "# Train the model on the training set:\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Investigate model accuracy for training and validation sets: \n",
    "train_predictions = model.predict(X_train) \n",
    "valid_predictions = model.predict(X_valid) \n",
    "\n",
    "print('Accuracy')\n",
    "print('Training set:', accuracy_score(y_train, train_predictions)) \n",
    "print('Validation set:', accuracy_score(y_valid, valid_predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest with 30 trees gave us slightly higher accuracy on the validation set (78.85%), let's try to raise the number of trees once more: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Training set: 0.9989626556016598\n",
      "Validation set: 0.7853810264385692\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with 50 trees: \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestClassifier(random_state=12345, n_estimators=50) \n",
    "\n",
    "# Train the model on the training set:\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Investigate model accuracy for training and validation sets: \n",
    "train_predictions = model.predict(X_train) \n",
    "valid_predictions = model.predict(X_valid) \n",
    "\n",
    "print('Accuracy')\n",
    "print('Training set:', accuracy_score(y_train, train_predictions)) \n",
    "print('Validation set:', accuracy_score(y_valid, valid_predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest with 50 trees kept raising the accuracy on the training set (10 trees: 97.72%, 30 trees: 99.64%, 50 trees: 99.9%) BUT the accuracy on the validation set - the important one - got slightly lower (only 78.54%). Since the default of RandomForestClassifier is 100 trees, let's investigate what accuracy it will produce:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Training set: 1.0\n",
      "Validation set: 0.7807153965785381\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with 100 trees: \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestClassifier(random_state=12345, n_estimators=100)\n",
    "                               \n",
    "\n",
    "# Train the model on the training set:\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Investigate model accuracy for training and validation sets: \n",
    "train_predictions = model.predict(X_train) \n",
    "valid_predictions = model.predict(X_valid) \n",
    "\n",
    "print('Accuracy')\n",
    "print('Training set:', accuracy_score(y_train, train_predictions)) \n",
    "print('Validation set:', accuracy_score(y_valid, valid_predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, with 100 trees the accuracy on the training set became perfect (100%), but the accuracy on the validation set - the important one - kept going down to 78.07%. Our best accuracy model so far is random forest with 30 trees (78.85%). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first try the model with most of it's default values for most hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Training set: 0.7121369294605809\n",
      "Validation set: 0.7060653188180405\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with 'liblinear' solver:  \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the model:\n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "\n",
    "# Train the model on the training set:\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Investigate model accuracy for training and validation sets: \n",
    "train_predictions = model.predict(X_train) \n",
    "valid_predictions = model.predict(X_valid) \n",
    "\n",
    "print('Accuracy')\n",
    "print('Training set:', accuracy_score(y_train, train_predictions)) \n",
    "print('Validation set:', accuracy_score(y_valid, valid_predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is disappointing, only 70.61% on validation set (and only 71.21 on training set), which is far under our defined threshold. It might say taht this kind of model fit's less to the currect kind of data. Let's try to change 3 hyperparameters and see if we get any serious improvement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Training set: 0.7505186721991701\n",
      "Validation set: 0.6625194401244168\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with solver='newton-cg', penalty='l2', C=0.5: \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the model:\n",
    "model = LogisticRegression(random_state=12345, solver='newton-cg', penalty='l2', C=0.5)\n",
    "\n",
    "# Train the model on the training set:\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Investigate model accuracy for training and validation sets: \n",
    "train_predictions = model.predict(X_train) \n",
    "valid_predictions = model.predict(X_test) \n",
    "\n",
    "print('Accuracy')\n",
    "print('Training set:', accuracy_score(y_train, train_predictions)) \n",
    "print('Validation set:', accuracy_score(y_valid, valid_predictions))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy on the validation set got even lower (only 66.25%) although the accuracy on the training set got higher (75.05%). It seems that logistic regression will not be our choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing our model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw, our best accuracy model so far was random forest with 30 trees, resulting in accuracy of 78.85% on the validation set. Before we check it on the test set - let's investigate if 40 trees will be better with accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Training set: 0.9984439834024896\n",
      "Validation set: 0.7822706065318819\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with 40 trees: \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestClassifier(random_state=12345, n_estimators=40) \n",
    "\n",
    "# Train the model on the training set:\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Investigate model accuracy for training and validation sets: \n",
    "train_predictions = model.predict(X_train) \n",
    "valid_predictions = model.predict(X_valid) \n",
    "\n",
    "print('Accuracy')\n",
    "print('Training set:', accuracy_score(y_train, train_predictions)) \n",
    "print('Validation set:', accuracy_score(y_valid, valid_predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, slightly less (78.83%). Maybe 20 trees will beat 30 trees with accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Training set: 0.9901452282157677\n",
      "Validation set: 0.7776049766718507\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with 20 trees: \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestClassifier(random_state=12345, n_estimators=20) \n",
    "\n",
    "# Train the model on the training set:\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Investigate model accuracy for training and validation sets: \n",
    "train_predictions = model.predict(X_train) \n",
    "valid_predictions = model.predict(X_valid) \n",
    "\n",
    "print('Accuracy')\n",
    "print('Training set:', accuracy_score(y_train, train_predictions)) \n",
    "print('Validation set:', accuracy_score(y_valid, valid_predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, we got back to only 77.76% accuracy on the validation set. We will stick to 30 trees! let's run it once again, to return our 'model' variable to our chosen one, before checking it on our test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Training set: 0.9963692946058091\n",
      "Validation set: 0.7884914463452566\n"
     ]
    }
   ],
   "source": [
    "# Running again our chosen model - Random Forest with 30 trees: \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestClassifier(random_state=12345, n_estimators=30) \n",
    "\n",
    "# Train the model on the training set:\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Investigate model accuracy for training and validation sets: \n",
    "train_predictions = model.predict(X_train) \n",
    "valid_predictions = model.predict(X_valid) \n",
    "\n",
    "print('Accuracy')\n",
    "print('Training set:', accuracy_score(y_train, train_predictions)) \n",
    "print('Validation set:', accuracy_score(y_valid, valid_predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the quality of the model using the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to check the accuracy of our chosen model - first time on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Test set: 0.80248833592535\n"
     ]
    }
   ],
   "source": [
    "# Checking the quality of our chosen model - first time using the test set: \n",
    "test_predictions = model.predict(X_test) \n",
    "\n",
    "print('Accuracy')\n",
    "print('Test set:', accuracy_score(y_test, test_predictions))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are ok, we needed to be at least on 75% accuracy checked on the test set, and we got 80.25%. Our chosen model of random forest classifier with 30 trees is ok for recommending a plan based on user behavior.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Project Goal**: **Develop a model** that will recommend the right plan (Ultra or Smart), based on behavior data about subscribers who have already switched to the new plans, **with the highest possible accuracy**. Managemnt defined that the **threshold for accuracy is 0.75** (checked on a test set that was not used at all for training). \n",
    "\n",
    "2. **Data**: Every observation in the dataset contains monthly behavior information about one user. We can see we have full 3214 entries (no missing values, no explicit duplicates, and datatypes are ok). The information given is as follows:\n",
    "- сalls — number of calls,\n",
    "- minutes — total call duration in minutes,\n",
    "- messages — number of text messages,\n",
    "- mb_used — Internet traffic used in MB,\n",
    "- is_ultra — plan for the current month (Ultra - 1, Smart - 0).\n",
    " \n",
    "3. **Data split**: data was randomly splitted to 3 sets, training set(60% of the data), validation set (20%), and test set (20%). \n",
    "\n",
    "4. **Investigatiing and developing models**: 3 kinds of models for classification were investigated: decision tree, random forset and logistic regression. For each kind hyperparameters were changed to investigate what model creates best accuracy on the validation set after being trined on the training set. \n",
    "\n",
    "5. **Chosen model**: the chosen model was random forest classifier with 30 trees, that created the best accuracy on the validation set (78.85%), and was above the defined threshold.\n",
    "\n",
    "6. **Accuracy check on the test set**: the accuracy of our chosen model, checked on the test set, is 80.25% or 0.8, which meets the project's requierments. \n",
    "\n",
    "7. **Overall conclusion**: a random forest classifier model was developed to recommend the right plan (Ultra or Smart), based on behavior data about subscribers who have already switched to the new plans. The model has accuracy of 0.8 and the project goal is achieved.   "
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1332,
    "start_time": "2022-03-03T12:11:28.497Z"
   },
   {
    "duration": 2029,
    "start_time": "2022-03-03T12:11:32.296Z"
   },
   {
    "duration": 1858,
    "start_time": "2022-03-03T12:16:01.479Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-03T12:33:11.430Z"
   },
   {
    "duration": 18,
    "start_time": "2022-03-03T12:33:24.091Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-03T12:33:54.101Z"
   },
   {
    "duration": 104,
    "start_time": "2022-03-03T13:29:51.169Z"
   },
   {
    "duration": 18,
    "start_time": "2022-03-03T13:33:52.815Z"
   },
   {
    "duration": 50,
    "start_time": "2022-03-03T14:18:36.371Z"
   },
   {
    "duration": 18,
    "start_time": "2022-03-03T14:19:43.876Z"
   },
   {
    "duration": 18,
    "start_time": "2022-03-03T14:20:52.450Z"
   },
   {
    "duration": 82,
    "start_time": "2022-03-03T15:31:31.821Z"
   },
   {
    "duration": 190,
    "start_time": "2022-03-03T15:32:15.310Z"
   },
   {
    "duration": 312,
    "start_time": "2022-03-03T15:34:44.450Z"
   },
   {
    "duration": 594,
    "start_time": "2022-03-03T15:35:18.729Z"
   },
   {
    "duration": 302,
    "start_time": "2022-03-03T15:35:32.907Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-03T15:37:00.449Z"
   },
   {
    "duration": 27,
    "start_time": "2022-03-03T15:40:43.132Z"
   },
   {
    "duration": 1066,
    "start_time": "2022-03-03T23:49:19.044Z"
   },
   {
    "duration": 19,
    "start_time": "2022-03-03T23:49:21.996Z"
   },
   {
    "duration": 69,
    "start_time": "2022-03-03T23:49:45.703Z"
   },
   {
    "duration": 733,
    "start_time": "2022-03-03T23:51:06.928Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-03T23:51:26.871Z"
   },
   {
    "duration": 419,
    "start_time": "2022-03-03T23:51:37.502Z"
   },
   {
    "duration": 584,
    "start_time": "2022-03-03T23:51:51.946Z"
   },
   {
    "duration": 809,
    "start_time": "2022-03-03T23:52:00.648Z"
   },
   {
    "duration": 151,
    "start_time": "2022-03-03T23:53:45.707Z"
   },
   {
    "duration": 154,
    "start_time": "2022-03-03T23:55:12.119Z"
   },
   {
    "duration": 149,
    "start_time": "2022-03-03T23:57:39.884Z"
   },
   {
    "duration": 59,
    "start_time": "2022-03-04T00:02:49.553Z"
   },
   {
    "duration": 87,
    "start_time": "2022-03-04T00:02:58.190Z"
   },
   {
    "duration": 94,
    "start_time": "2022-03-04T00:03:55.349Z"
   },
   {
    "duration": 82,
    "start_time": "2022-03-04T00:06:39.627Z"
   },
   {
    "duration": 82,
    "start_time": "2022-03-04T00:07:45.491Z"
   },
   {
    "duration": 78,
    "start_time": "2022-03-04T00:09:00.839Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-04T00:11:00.452Z"
   },
   {
    "duration": 995,
    "start_time": "2022-03-06T06:37:49.278Z"
   },
   {
    "duration": 20,
    "start_time": "2022-03-06T06:37:50.274Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-06T06:37:50.295Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-06T06:37:50.308Z"
   },
   {
    "duration": 56,
    "start_time": "2022-03-06T06:37:50.315Z"
   },
   {
    "duration": 32,
    "start_time": "2022-03-06T06:38:27.946Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-06T06:38:53.542Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-06T06:38:58.033Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-06T06:39:43.478Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-06T06:40:11.618Z"
   },
   {
    "duration": 52,
    "start_time": "2022-03-06T06:40:58.515Z"
   },
   {
    "duration": 115,
    "start_time": "2022-03-06T06:41:38.460Z"
   },
   {
    "duration": 185,
    "start_time": "2022-03-06T06:41:51.444Z"
   },
   {
    "duration": 138,
    "start_time": "2022-03-06T06:42:16.400Z"
   },
   {
    "duration": 137,
    "start_time": "2022-03-06T06:42:41.356Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-06T06:44:22.188Z"
   },
   {
    "duration": 24,
    "start_time": "2022-03-06T06:44:22.193Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-06T06:44:22.219Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-06T06:44:22.228Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-06T06:44:22.235Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-06T06:44:22.246Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-06T06:44:22.257Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-06T06:44:22.267Z"
   },
   {
    "duration": 45,
    "start_time": "2022-03-06T06:44:22.301Z"
   },
   {
    "duration": 127,
    "start_time": "2022-03-06T06:44:22.347Z"
   },
   {
    "duration": 193,
    "start_time": "2022-03-06T06:44:22.475Z"
   },
   {
    "duration": 989,
    "start_time": "2022-03-06T06:44:54.670Z"
   },
   {
    "duration": 18,
    "start_time": "2022-03-06T06:44:55.661Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-06T06:44:55.681Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-06T06:44:55.692Z"
   },
   {
    "duration": 56,
    "start_time": "2022-03-06T06:44:55.700Z"
   },
   {
    "duration": 30,
    "start_time": "2022-03-06T06:44:55.757Z"
   },
   {
    "duration": 19,
    "start_time": "2022-03-06T06:44:55.788Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-06T06:44:55.809Z"
   },
   {
    "duration": 49,
    "start_time": "2022-03-06T06:44:55.820Z"
   },
   {
    "duration": 135,
    "start_time": "2022-03-06T06:44:55.870Z"
   },
   {
    "duration": 196,
    "start_time": "2022-03-06T06:44:56.007Z"
   },
   {
    "duration": 355,
    "start_time": "2022-03-06T06:45:24.069Z"
   },
   {
    "duration": 14,
    "start_time": "2022-03-06T06:48:19.395Z"
   },
   {
    "duration": 94,
    "start_time": "2022-03-06T06:51:58.585Z"
   },
   {
    "duration": 111,
    "start_time": "2022-03-06T06:54:22.324Z"
   },
   {
    "duration": 114,
    "start_time": "2022-03-06T07:15:21.782Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-06T07:15:50.856Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-06T07:59:43.218Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-06T08:22:51.787Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-06T08:25:06.110Z"
   },
   {
    "duration": 156,
    "start_time": "2022-03-06T08:57:45.624Z"
   },
   {
    "duration": 80,
    "start_time": "2022-03-06T08:58:43.030Z"
   },
   {
    "duration": 114,
    "start_time": "2022-03-06T09:03:35.462Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-06T09:04:35.061Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-06T09:17:55.474Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
